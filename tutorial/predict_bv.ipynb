{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Import necessary libraries and modules\n",
    "# =============================================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import custom modules\n",
    "from config import Config\n",
    "from data.data_utils import (\n",
    "    load_genotype_data, apply_missing_mask, encode_genotype_to_categorical,\n",
    "    load_phenotype_data, preprocess_phenotype_data, GenotypeDataset, PhenotypeDataset,\n",
    "    prepare_pretraining_data\n",
    ")\n",
    "\n",
    "from model.model_utils import (\n",
    "    CMDAutoEncoder, CMDPhenotypePredictor, train_autoencoder, evaluate_autoencoder,\n",
    "    train_phenotype_predictor, evaluate_phenotype_predictor, set_random_seed,\n",
    "    load_pretrained_weights, pretrain_autoencoder\n",
    ")\n",
    "\n",
    "from train.cross_train import cross_validation_phenotype_prediction\n",
    "from train.evaluation_utils import (\n",
    "    calculate_runtime_summary, print_final_results\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMD Genotype-Phenotype Association Analysis System\n",
    "\n",
    "## System Overview\n",
    "This notebook implements a genotype-phenotype association analysis system based on CMD architecture, supporting pre-training and 10-fold cross-validation.\n",
    "\n",
    "## Main Features\n",
    "- **Pre-training Model**: Uses autoencoder for genotype data pre-training\n",
    "- **Phenotype Prediction**: Predicts phenotype values based on pre-trained features\n",
    "- **Cross-validation**: Supports 10-fold cross-validation for model performance evaluation\n",
    "- **Early Stopping**: Early stopping strategy to prevent overfitting\n",
    "\n",
    "## Configuration Description\n",
    "All configuration parameters are centralized in the `Config` class, including:\n",
    "- `USE_PRETRAINED`: Whether to use pre-trained model\n",
    "- `MISSING_RATIO`: Missing data ratio\n",
    "- `EPOCHS`: Number of training epochs\n",
    "- `EARLY_STOPPING_PATIENCE`: Early stopping patience value\n",
    "\n",
    "## Usage Workflow\n",
    "1. **Data Preprocessing**: Load and preprocess genotype data\n",
    "2. **Pre-training Phase**: Train autoencoder model (optional)\n",
    "3. **Phenotype Prediction**: Train phenotype prediction model\n",
    "4. **Cross-validation**: 10-fold cross-validation for performance evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotype data shape: (1000, 20000)\n",
      "Phenotype data shape: (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Data loading and preprocessing\n",
    "# =============================================================================\n",
    "\n",
    "# Load data\n",
    "genotype_file = './dataset/test_geno.csv'\n",
    "phenotype_file= \"./dataset/test_pheno.csv\"\n",
    "\n",
    "\n",
    "df_ori = load_genotype_data(genotype_file, max_rows=config.MAX_ROWS)\n",
    "print(f\"Genotype data shape: {df_ori.shape}\")\n",
    "\n",
    "phenotype_data = load_phenotype_data(phenotype_file)\n",
    "print(f\"Phenotype data shape: {phenotype_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ratio: 0.0\n",
      "Masked data shape: (1000, 20000)\n",
      "Encoded data shape: (1000, 20000, 3)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Data preprocessing\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Apply data preprocessing\n",
    "mask_data = apply_missing_mask(df_ori, config.MISSING_RATIO)\n",
    "print(f\"Missing ratio: {config.MISSING_RATIO}\")\n",
    "# Create DataFrame for masked data\n",
    "mask_data_copy = pd.DataFrame(mask_data)\n",
    "mask_data_copy.index = df_ori.index\n",
    "print(f\"Masked data shape: {mask_data_copy.shape}\")\n",
    "# Encode genotype data to categorical format\n",
    "df_onehot = encode_genotype_to_categorical(mask_data)\n",
    "df_onehot_no_miss = encode_genotype_to_categorical(df_ori.to_numpy())\n",
    "print(f\"Encoded data shape: {df_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape: (1000, 20000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Verify data shape\n",
    "print(f\"Encoded data shape: {df_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Data splitting and model initialization\n",
    "# =============================================================================\n",
    "\n",
    "# Prepare pre-training data\n",
    "train_loader, valid_loader = prepare_pretraining_data(\n",
    "    df_onehot, df_onehot_no_miss, \n",
    "    test_size=0.1, random_seed=config.RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting autoencoder pre-training...\n",
      "Epoch 1/100 - Training accuracy: 0.77812, Validation accuracy: 0.87981, Loss: 0.56752993\n",
      "Epoch 2/100 - Training accuracy: 0.92155, Validation accuracy: 0.94908, Loss: 0.20536899\n",
      "Epoch 3/100 - Training accuracy: 0.96079, Validation accuracy: 0.96993, Loss: 0.09992990\n",
      "Epoch 4/100 - Training accuracy: 0.97685, Validation accuracy: 0.98156, Loss: 0.06405237\n",
      "Epoch 5/100 - Training accuracy: 0.98363, Validation accuracy: 0.98845, Loss: 0.04666885\n",
      "Epoch 6/100 - Training accuracy: 0.98933, Validation accuracy: 0.99087, Loss: 0.03129701\n",
      "Epoch 7/100 - Training accuracy: 0.99144, Validation accuracy: 0.99194, Loss: 0.02607300\n",
      "Epoch 8/100 - Training accuracy: 0.99231, Validation accuracy: 0.99256, Loss: 0.02315861\n",
      "Epoch 9/100 - Training accuracy: 0.99281, Validation accuracy: 0.99290, Loss: 0.02109643\n",
      "Epoch 10/100 - Training accuracy: 0.99333, Validation accuracy: 0.99369, Loss: 0.01958372\n",
      "Epoch 11/100 - Training accuracy: 0.99331, Validation accuracy: 0.99388, Loss: 0.01877088\n",
      "Epoch 12/100 - Training accuracy: 0.99391, Validation accuracy: 0.99408, Loss: 0.01696458\n",
      "Epoch 13/100 - Training accuracy: 0.99395, Validation accuracy: 0.99470, Loss: 0.01588552\n",
      "Epoch 14/100 - Training accuracy: 0.99432, Validation accuracy: 0.99562, Loss: 0.01544721\n",
      "Epoch 15/100 - Training accuracy: 0.99579, Validation accuracy: 0.99594, Loss: 0.01176395\n",
      "Epoch 16/100 - Training accuracy: 0.99622, Validation accuracy: 0.99638, Loss: 0.00993078\n",
      "Epoch 17/100 - Training accuracy: 0.99638, Validation accuracy: 0.99656, Loss: 0.00920625\n",
      "Epoch 18/100 - Training accuracy: 0.99708, Validation accuracy: 0.99743, Loss: 0.00825643\n",
      "Epoch 19/100 - Training accuracy: 0.99768, Validation accuracy: 0.99773, Loss: 0.00720163\n",
      "Epoch 20/100 - Training accuracy: 0.99783, Validation accuracy: 0.99786, Loss: 0.00661439\n",
      "Epoch 21/100 - Training accuracy: 0.99789, Validation accuracy: 0.99777, Loss: 0.00633239\n",
      "Epoch 22/100 - Training accuracy: 0.99788, Validation accuracy: 0.99790, Loss: 0.00607866\n",
      "Epoch 23/100 - Training accuracy: 0.99780, Validation accuracy: 0.99800, Loss: 0.00608001\n",
      "Epoch 24/100 - Training accuracy: 0.99786, Validation accuracy: 0.99784, Loss: 0.00583491\n",
      "Epoch 25/100 - Training accuracy: 0.99793, Validation accuracy: 0.99778, Loss: 0.00558152\n",
      "Epoch 26/100 - Training accuracy: 0.99794, Validation accuracy: 0.99793, Loss: 0.00546789\n",
      "Epoch 27/100 - Training accuracy: 0.99797, Validation accuracy: 0.99795, Loss: 0.00527570\n",
      "Epoch 28/100 - Training accuracy: 0.99794, Validation accuracy: 0.99780, Loss: 0.00529241\n",
      "Epoch 29/100 - Training accuracy: 0.99795, Validation accuracy: 0.99802, Loss: 0.00514828\n",
      "Epoch 30/100 - Training accuracy: 0.99795, Validation accuracy: 0.99774, Loss: 0.00507249\n",
      "Epoch 31/100 - Training accuracy: 0.99769, Validation accuracy: 0.99748, Loss: 0.00569476\n",
      "Epoch 32/100 - Training accuracy: 0.99790, Validation accuracy: 0.99782, Loss: 0.00501588\n",
      "Epoch 33/100 - Training accuracy: 0.99804, Validation accuracy: 0.99810, Loss: 0.00476040\n",
      "Epoch 34/100 - Training accuracy: 0.99806, Validation accuracy: 0.99800, Loss: 0.00466791\n",
      "Epoch 35/100 - Training accuracy: 0.99806, Validation accuracy: 0.99807, Loss: 0.00460491\n",
      "Epoch 36/100 - Training accuracy: 0.99805, Validation accuracy: 0.99804, Loss: 0.00454057\n",
      "Epoch 37/100 - Training accuracy: 0.99802, Validation accuracy: 0.99765, Loss: 0.00458519\n",
      "Epoch 38/100 - Training accuracy: 0.97367, Validation accuracy: 0.97650, Loss: 0.14528746\n",
      "Epoch 39/100 - Training accuracy: 0.98398, Validation accuracy: 0.98781, Loss: 0.04270976\n",
      "Epoch 40/100 - Training accuracy: 0.98987, Validation accuracy: 0.99186, Loss: 0.02478866\n",
      "Epoch 41/100 - Training accuracy: 0.99235, Validation accuracy: 0.99281, Loss: 0.01960499\n",
      "Epoch 42/100 - Training accuracy: 0.99296, Validation accuracy: 0.99308, Loss: 0.01697646\n",
      "Epoch 43/100 - Training accuracy: 0.99320, Validation accuracy: 0.99330, Loss: 0.01530621\n",
      "Epoch 44/100 - Training accuracy: 0.99345, Validation accuracy: 0.99358, Loss: 0.01416505\n",
      "Epoch 45/100 - Training accuracy: 0.99367, Validation accuracy: 0.99374, Loss: 0.01327491\n",
      "Epoch 46/100 - Training accuracy: 0.99390, Validation accuracy: 0.99412, Loss: 0.01237115\n",
      "Epoch 47/100 - Training accuracy: 0.99423, Validation accuracy: 0.99431, Loss: 0.01142276\n",
      "Epoch 48/100 - Training accuracy: 0.99517, Validation accuracy: 0.99707, Loss: 0.01011203\n",
      "Epoch 49/100 - Training accuracy: 0.99732, Validation accuracy: 0.99770, Loss: 0.00820010\n",
      "Epoch 50/100 - Training accuracy: 0.99779, Validation accuracy: 0.99789, Loss: 0.00643437\n",
      "Epoch 51/100 - Training accuracy: 0.99793, Validation accuracy: 0.99793, Loss: 0.00571264\n",
      "Epoch 52/100 - Training accuracy: 0.99797, Validation accuracy: 0.99796, Loss: 0.00525699\n",
      "Epoch 53/100 - Training accuracy: 0.99799, Validation accuracy: 0.99799, Loss: 0.00502558\n",
      "Epoch 54/100 - Training accuracy: 0.99802, Validation accuracy: 0.99802, Loss: 0.00486062\n",
      "Epoch 55/100 - Training accuracy: 0.99803, Validation accuracy: 0.99802, Loss: 0.00476374\n",
      "Epoch 56/100 - Training accuracy: 0.99805, Validation accuracy: 0.99804, Loss: 0.00462259\n",
      "Epoch 57/100 - Training accuracy: 0.99807, Validation accuracy: 0.99804, Loss: 0.00453949\n",
      "Epoch 58/100 - Training accuracy: 0.99809, Validation accuracy: 0.99809, Loss: 0.00441633\n",
      "Epoch 59/100 - Training accuracy: 0.99811, Validation accuracy: 0.99810, Loss: 0.00432708\n",
      "Epoch 60/100 - Training accuracy: 0.99812, Validation accuracy: 0.99811, Loss: 0.00431290\n",
      "Epoch 61/100 - Training accuracy: 0.99814, Validation accuracy: 0.99809, Loss: 0.00422422\n",
      "Epoch 62/100 - Training accuracy: 0.99816, Validation accuracy: 0.99814, Loss: 0.00414874\n",
      "Epoch 63/100 - Training accuracy: 0.99818, Validation accuracy: 0.99816, Loss: 0.00413397\n",
      "Epoch 64/100 - Training accuracy: 0.99820, Validation accuracy: 0.99821, Loss: 0.00402061\n",
      "Epoch 65/100 - Training accuracy: 0.99823, Validation accuracy: 0.99822, Loss: 0.00402120\n",
      "Epoch 66/100 - Training accuracy: 0.99824, Validation accuracy: 0.99820, Loss: 0.00395887\n",
      "Epoch 67/100 - Training accuracy: 0.99825, Validation accuracy: 0.99824, Loss: 0.00384876\n",
      "Epoch 68/100 - Training accuracy: 0.99826, Validation accuracy: 0.99823, Loss: 0.00383117\n",
      "Epoch 69/100 - Training accuracy: 0.99827, Validation accuracy: 0.99827, Loss: 0.00379647\n",
      "Epoch 70/100 - Training accuracy: 0.99828, Validation accuracy: 0.99827, Loss: 0.00375460\n",
      "Epoch 71/100 - Training accuracy: 0.99828, Validation accuracy: 0.99826, Loss: 0.00367814\n",
      "Epoch 72/100 - Training accuracy: 0.99829, Validation accuracy: 0.99829, Loss: 0.00364437\n",
      "Epoch 73/100 - Training accuracy: 0.99829, Validation accuracy: 0.99826, Loss: 0.00359645\n",
      "Epoch 74/100 - Training accuracy: 0.99830, Validation accuracy: 0.99828, Loss: 0.00357302\n",
      "Epoch 75/100 - Training accuracy: 0.99831, Validation accuracy: 0.99826, Loss: 0.00349751\n",
      "Epoch 76/100 - Training accuracy: 0.99831, Validation accuracy: 0.99830, Loss: 0.00351129\n",
      "Epoch 77/100 - Training accuracy: 0.99831, Validation accuracy: 0.99828, Loss: 0.00345034\n",
      "Epoch 78/100 - Training accuracy: 0.99831, Validation accuracy: 0.99830, Loss: 0.00343024\n",
      "Epoch 79/100 - Training accuracy: 0.99832, Validation accuracy: 0.99828, Loss: 0.00338608\n",
      "Epoch 80/100 - Training accuracy: 0.99832, Validation accuracy: 0.99830, Loss: 0.00334194\n",
      "Epoch 81/100 - Training accuracy: 0.99832, Validation accuracy: 0.99829, Loss: 0.00330144\n",
      "Epoch 82/100 - Training accuracy: 0.99832, Validation accuracy: 0.99830, Loss: 0.00325657\n",
      "Epoch 83/100 - Training accuracy: 0.99833, Validation accuracy: 0.99829, Loss: 0.00325234\n",
      "Epoch 84/100 - Training accuracy: 0.99833, Validation accuracy: 0.99831, Loss: 0.00323930\n",
      "Epoch 85/100 - Training accuracy: 0.99834, Validation accuracy: 0.99833, Loss: 0.00316835\n",
      "Epoch 86/100 - Training accuracy: 0.99834, Validation accuracy: 0.99830, Loss: 0.00314975\n",
      "Epoch 87/100 - Training accuracy: 0.99835, Validation accuracy: 0.99827, Loss: 0.00314373\n",
      "Epoch 88/100 - Training accuracy: 0.99835, Validation accuracy: 0.99833, Loss: 0.00309434\n",
      "Epoch 89/100 - Training accuracy: 0.99836, Validation accuracy: 0.99835, Loss: 0.00307146\n",
      "Epoch 90/100 - Training accuracy: 0.99837, Validation accuracy: 0.99838, Loss: 0.00305331\n",
      "Epoch 91/100 - Training accuracy: 0.99836, Validation accuracy: 0.99809, Loss: 0.00305180\n",
      "Epoch 92/100 - Training accuracy: 0.99836, Validation accuracy: 0.99838, Loss: 0.00302544\n",
      "Epoch 93/100 - Training accuracy: 0.99839, Validation accuracy: 0.99836, Loss: 0.00299568\n",
      "Epoch 94/100 - Training accuracy: 0.99840, Validation accuracy: 0.99837, Loss: 0.00296051\n",
      "Epoch 95/100 - Training accuracy: 0.99841, Validation accuracy: 0.99835, Loss: 0.00296827\n",
      "Epoch 96/100 - Training accuracy: 0.99841, Validation accuracy: 0.99838, Loss: 0.00290512\n",
      "Epoch 97/100 - Training accuracy: 0.99840, Validation accuracy: 0.99838, Loss: 0.00287135\n",
      "Epoch 98/100 - Training accuracy: 0.99839, Validation accuracy: 0.99837, Loss: 0.00287135\n",
      "Epoch 99/100 - Training accuracy: 0.99842, Validation accuracy: 0.99837, Loss: 0.00283820\n",
      "Epoch 100/100 - Training accuracy: 0.99842, Validation accuracy: 0.99837, Loss: 0.00278634\n",
      "Pre-training completed! Best model saved at: ./model/model_state.pth\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Pre-training phase\n",
    "# =============================================================================\n",
    "\n",
    "# Execute pre-training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model_path = pretrain_autoencoder(train_loader, valid_loader, device, config.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenotype column name: AL\n",
      "After normalization - Mean: -0.0000, Std: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Phenotype data preprocessing\n",
    "# =============================================================================\n",
    "\n",
    "# Preprocess phenotype data\n",
    "genotype_encoded, phenotype_normalized, phenotype_scaler = preprocess_phenotype_data(\n",
    "    phenotype_data, mask_data_copy, phenotype_column=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Cross-validation Fold 1/10 ==========\n",
      "🔄 Fold 1: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 0.988895\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 0.570745\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 0.347812\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.297578\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.404415\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.657877\n",
      "=========> Epoch: 1 Average loss: 0.6881\n",
      "Correlation coefficient: 0.5562\n",
      "✅ Epoch 1: New best correlation = 0.5562\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.178797\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.423132\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.254153\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.183533\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.139854\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.233295\n",
      "=========> Epoch: 2 Average loss: 0.2968\n",
      "Correlation coefficient: 0.4859\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.061522\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.146873\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.021589\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.074094\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.099961\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.077705\n",
      "=========> Epoch: 3 Average loss: 0.0944\n",
      "Correlation coefficient: 0.5132\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.058558\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.014567\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.036157\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.044844\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.039902\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.036828\n",
      "=========> Epoch: 4 Average loss: 0.0455\n",
      "Correlation coefficient: 0.5083\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.031505\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.007776\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.009270\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.042210\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.017071\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.029344\n",
      "=========> Epoch: 5 Average loss: 0.0229\n",
      "Correlation coefficient: 0.5173\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.007866\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.006830\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.012198\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.006335\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.016530\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.012107\n",
      "=========> Epoch: 6 Average loss: 0.0112\n",
      "Correlation coefficient: 0.5175\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.009641\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.005980\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.009336\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.003771\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.002375\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.004851\n",
      "=========> Epoch: 7 Average loss: 0.0070\n",
      "Correlation coefficient: 0.5332\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.005860\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.004115\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.008879\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.003648\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.002676\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.013588\n",
      "=========> Epoch: 8 Average loss: 0.0064\n",
      "Correlation coefficient: 0.5210\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.002791\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.003168\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.004980\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.009991\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.015265\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.003948\n",
      "=========> Epoch: 9 Average loss: 0.0068\n",
      "Correlation coefficient: 0.5279\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.003819\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.002542\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.003807\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.007022\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.004560\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.010720\n",
      "=========> Epoch: 10 Average loss: 0.0087\n",
      "Correlation coefficient: 0.5206\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.010272\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.001911\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.010409\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.007252\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.014456\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.005941\n",
      "=========> Epoch: 11 Average loss: 0.0108\n",
      "Correlation coefficient: 0.5261\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.004663\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.006484\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.010813\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.013548\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.014854\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.015817\n",
      "=========> Epoch: 12 Average loss: 0.0112\n",
      "Correlation coefficient: 0.5251\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.003759\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.011430\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.009590\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.024211\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.011564\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.026985\n",
      "=========> Epoch: 13 Average loss: 0.0120\n",
      "Correlation coefficient: 0.5209\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.005446\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.009968\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.004472\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.010267\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.008311\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.020821\n",
      "=========> Epoch: 14 Average loss: 0.0140\n",
      "Correlation coefficient: 0.5338\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.014256\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.028269\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.020497\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.013686\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.006471\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.011187\n",
      "=========> Epoch: 15 Average loss: 0.0159\n",
      "Correlation coefficient: 0.5248\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.012933\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.009393\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.014273\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.008598\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.010856\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.023969\n",
      "=========> Epoch: 16 Average loss: 0.0166\n",
      "Correlation coefficient: 0.5171\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.014523\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.037690\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.007129\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.023895\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.018232\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.006966\n",
      "=========> Epoch: 17 Average loss: 0.0193\n",
      "Correlation coefficient: 0.5268\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.015348\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.047721\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.027426\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.024405\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.014768\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.012656\n",
      "=========> Epoch: 18 Average loss: 0.0235\n",
      "Correlation coefficient: 0.5194\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.021659\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.032038\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.014680\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.033806\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.017916\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.026083\n",
      "=========> Epoch: 19 Average loss: 0.0268\n",
      "Correlation coefficient: 0.5279\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.012268\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.017341\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.052209\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.010393\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.009560\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.016127\n",
      "=========> Epoch: 20 Average loss: 0.0267\n",
      "Correlation coefficient: 0.5304\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.022841\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.033465\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.023416\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.022881\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.018165\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.037247\n",
      "=========> Epoch: 21 Average loss: 0.0322\n",
      "Correlation coefficient: 0.5246\n",
      "⏹️  Epoch 21 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 1 best correlation: 0.5562\n",
      "\n",
      "========== Cross-validation Fold 2/10 ==========\n",
      "🔄 Fold 2: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 0.649763\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 1.681672\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 0.521957\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.625607\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.505250\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.536373\n",
      "=========> Epoch: 1 Average loss: 0.8462\n",
      "Correlation coefficient: 0.7601\n",
      "✅ Epoch 1: New best correlation = 0.7601\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.377920\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.807605\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.219092\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.441321\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.273737\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.179357\n",
      "=========> Epoch: 2 Average loss: 0.3812\n",
      "Correlation coefficient: 0.7614\n",
      "✅ Epoch 2: New best correlation = 0.7614\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.075804\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.123413\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.083725\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.077900\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.138204\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.046275\n",
      "=========> Epoch: 3 Average loss: 0.1208\n",
      "Correlation coefficient: 0.7470\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.066594\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.064704\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.054760\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.087872\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.048758\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.041583\n",
      "=========> Epoch: 4 Average loss: 0.0571\n",
      "Correlation coefficient: 0.7543\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.089910\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.049216\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.028974\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.024992\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.018937\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.024392\n",
      "=========> Epoch: 5 Average loss: 0.0304\n",
      "Correlation coefficient: 0.7469\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.027015\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.010902\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.012376\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.011329\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.017080\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.024357\n",
      "=========> Epoch: 6 Average loss: 0.0194\n",
      "Correlation coefficient: 0.7583\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.008682\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.017763\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.025215\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.009656\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.013430\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.023607\n",
      "=========> Epoch: 7 Average loss: 0.0149\n",
      "Correlation coefficient: 0.7592\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.002627\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.005168\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.014591\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.007267\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.003816\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.004556\n",
      "=========> Epoch: 8 Average loss: 0.0093\n",
      "Correlation coefficient: 0.7572\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.004089\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.005035\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.012268\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.007753\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.005034\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.030717\n",
      "=========> Epoch: 9 Average loss: 0.0109\n",
      "Correlation coefficient: 0.7609\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.003836\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.008742\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.005982\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.005239\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.015375\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.004128\n",
      "=========> Epoch: 10 Average loss: 0.0072\n",
      "Correlation coefficient: 0.7563\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.005811\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.002674\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.006243\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.007457\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.002840\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.005347\n",
      "=========> Epoch: 11 Average loss: 0.0063\n",
      "Correlation coefficient: 0.7613\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.006918\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.002903\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.004470\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.004234\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.002255\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.006535\n",
      "=========> Epoch: 12 Average loss: 0.0058\n",
      "Correlation coefficient: 0.7599\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.008544\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.005590\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.003890\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.056304\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.007920\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.004464\n",
      "=========> Epoch: 13 Average loss: 0.0072\n",
      "Correlation coefficient: 0.7659\n",
      "✅ Epoch 13: New best correlation = 0.7659\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.006946\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.010324\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.010566\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.010555\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.003620\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.002847\n",
      "=========> Epoch: 14 Average loss: 0.0089\n",
      "Correlation coefficient: 0.7595\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.003845\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.007835\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.007630\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.012626\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.007773\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.015422\n",
      "=========> Epoch: 15 Average loss: 0.0100\n",
      "Correlation coefficient: 0.7594\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.008795\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.011269\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.014056\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.008448\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.005404\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.004908\n",
      "=========> Epoch: 16 Average loss: 0.0078\n",
      "Correlation coefficient: 0.7568\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.005413\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.009815\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.005164\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.002878\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.007208\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.005161\n",
      "=========> Epoch: 17 Average loss: 0.0067\n",
      "Correlation coefficient: 0.7610\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.003094\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.008187\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.003862\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.007852\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.008271\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.005868\n",
      "=========> Epoch: 18 Average loss: 0.0079\n",
      "Correlation coefficient: 0.7568\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.005160\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.011339\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.009796\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.008242\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.005175\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.003710\n",
      "=========> Epoch: 19 Average loss: 0.0105\n",
      "Correlation coefficient: 0.7585\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.009438\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.017655\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.038488\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.034302\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.018000\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.013442\n",
      "=========> Epoch: 20 Average loss: 0.0194\n",
      "Correlation coefficient: 0.7582\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.038471\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.008213\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.018546\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.015480\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.030097\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.017284\n",
      "=========> Epoch: 21 Average loss: 0.0234\n",
      "Correlation coefficient: 0.7514\n",
      "Training epoch: 22 [0/900 (0%)]\tLoss: 0.009520\n",
      "Training epoch: 22 [160/900 (18%)]\tLoss: 0.047415\n",
      "Training epoch: 22 [320/900 (35%)]\tLoss: 0.010948\n",
      "Training epoch: 22 [480/900 (53%)]\tLoss: 0.017727\n",
      "Training epoch: 22 [640/900 (70%)]\tLoss: 0.014825\n",
      "Training epoch: 22 [800/900 (88%)]\tLoss: 0.006427\n",
      "=========> Epoch: 22 Average loss: 0.0239\n",
      "Correlation coefficient: 0.7529\n",
      "Training epoch: 23 [0/900 (0%)]\tLoss: 0.027724\n",
      "Training epoch: 23 [160/900 (18%)]\tLoss: 0.029381\n",
      "Training epoch: 23 [320/900 (35%)]\tLoss: 0.015582\n",
      "Training epoch: 23 [480/900 (53%)]\tLoss: 0.028359\n",
      "Training epoch: 23 [640/900 (70%)]\tLoss: 0.018301\n",
      "Training epoch: 23 [800/900 (88%)]\tLoss: 0.020804\n",
      "=========> Epoch: 23 Average loss: 0.0222\n",
      "Correlation coefficient: 0.7628\n",
      "Training epoch: 24 [0/900 (0%)]\tLoss: 0.016175\n",
      "Training epoch: 24 [160/900 (18%)]\tLoss: 0.008512\n",
      "Training epoch: 24 [320/900 (35%)]\tLoss: 0.008681\n",
      "Training epoch: 24 [480/900 (53%)]\tLoss: 0.007342\n",
      "Training epoch: 24 [640/900 (70%)]\tLoss: 0.006155\n",
      "Training epoch: 24 [800/900 (88%)]\tLoss: 0.021507\n",
      "=========> Epoch: 24 Average loss: 0.0141\n",
      "Correlation coefficient: 0.7623\n",
      "Training epoch: 25 [0/900 (0%)]\tLoss: 0.009353\n",
      "Training epoch: 25 [160/900 (18%)]\tLoss: 0.005134\n",
      "Training epoch: 25 [320/900 (35%)]\tLoss: 0.009374\n",
      "Training epoch: 25 [480/900 (53%)]\tLoss: 0.005008\n",
      "Training epoch: 25 [640/900 (70%)]\tLoss: 0.004783\n",
      "Training epoch: 25 [800/900 (88%)]\tLoss: 0.007572\n",
      "=========> Epoch: 25 Average loss: 0.0080\n",
      "Correlation coefficient: 0.7538\n",
      "Training epoch: 26 [0/900 (0%)]\tLoss: 0.008232\n",
      "Training epoch: 26 [160/900 (18%)]\tLoss: 0.001732\n",
      "Training epoch: 26 [320/900 (35%)]\tLoss: 0.004523\n",
      "Training epoch: 26 [480/900 (53%)]\tLoss: 0.009042\n",
      "Training epoch: 26 [640/900 (70%)]\tLoss: 0.006172\n",
      "Training epoch: 26 [800/900 (88%)]\tLoss: 0.004116\n",
      "=========> Epoch: 26 Average loss: 0.0057\n",
      "Correlation coefficient: 0.7636\n",
      "Training epoch: 27 [0/900 (0%)]\tLoss: 0.002541\n",
      "Training epoch: 27 [160/900 (18%)]\tLoss: 0.003226\n",
      "Training epoch: 27 [320/900 (35%)]\tLoss: 0.006920\n",
      "Training epoch: 27 [480/900 (53%)]\tLoss: 0.008751\n",
      "Training epoch: 27 [640/900 (70%)]\tLoss: 0.002414\n",
      "Training epoch: 27 [800/900 (88%)]\tLoss: 0.007546\n",
      "=========> Epoch: 27 Average loss: 0.0045\n",
      "Correlation coefficient: 0.7629\n",
      "Training epoch: 28 [0/900 (0%)]\tLoss: 0.003605\n",
      "Training epoch: 28 [160/900 (18%)]\tLoss: 0.003750\n",
      "Training epoch: 28 [320/900 (35%)]\tLoss: 0.002747\n",
      "Training epoch: 28 [480/900 (53%)]\tLoss: 0.001159\n",
      "Training epoch: 28 [640/900 (70%)]\tLoss: 0.001959\n",
      "Training epoch: 28 [800/900 (88%)]\tLoss: 0.002903\n",
      "=========> Epoch: 28 Average loss: 0.0035\n",
      "Correlation coefficient: 0.7629\n",
      "Training epoch: 29 [0/900 (0%)]\tLoss: 0.007176\n",
      "Training epoch: 29 [160/900 (18%)]\tLoss: 0.003030\n",
      "Training epoch: 29 [320/900 (35%)]\tLoss: 0.001473\n",
      "Training epoch: 29 [480/900 (53%)]\tLoss: 0.002993\n",
      "Training epoch: 29 [640/900 (70%)]\tLoss: 0.004647\n",
      "Training epoch: 29 [800/900 (88%)]\tLoss: 0.001581\n",
      "=========> Epoch: 29 Average loss: 0.0023\n",
      "Correlation coefficient: 0.7638\n",
      "Training epoch: 30 [0/900 (0%)]\tLoss: 0.001248\n",
      "Training epoch: 30 [160/900 (18%)]\tLoss: 0.003081\n",
      "Training epoch: 30 [320/900 (35%)]\tLoss: 0.001731\n",
      "Training epoch: 30 [480/900 (53%)]\tLoss: 0.001483\n",
      "Training epoch: 30 [640/900 (70%)]\tLoss: 0.023601\n",
      "Training epoch: 30 [800/900 (88%)]\tLoss: 0.004956\n",
      "=========> Epoch: 30 Average loss: 0.0026\n",
      "Correlation coefficient: 0.7651\n",
      "Training epoch: 31 [0/900 (0%)]\tLoss: 0.002507\n",
      "Training epoch: 31 [160/900 (18%)]\tLoss: 0.004386\n",
      "Training epoch: 31 [320/900 (35%)]\tLoss: 0.000985\n",
      "Training epoch: 31 [480/900 (53%)]\tLoss: 0.002644\n",
      "Training epoch: 31 [640/900 (70%)]\tLoss: 0.012881\n",
      "Training epoch: 31 [800/900 (88%)]\tLoss: 0.007357\n",
      "=========> Epoch: 31 Average loss: 0.0033\n",
      "Correlation coefficient: 0.7637\n",
      "Training epoch: 32 [0/900 (0%)]\tLoss: 0.007512\n",
      "Training epoch: 32 [160/900 (18%)]\tLoss: 0.001816\n",
      "Training epoch: 32 [320/900 (35%)]\tLoss: 0.003382\n",
      "Training epoch: 32 [480/900 (53%)]\tLoss: 0.001915\n",
      "Training epoch: 32 [640/900 (70%)]\tLoss: 0.007059\n",
      "Training epoch: 32 [800/900 (88%)]\tLoss: 0.004093\n",
      "=========> Epoch: 32 Average loss: 0.0040\n",
      "Correlation coefficient: 0.7582\n",
      "Training epoch: 33 [0/900 (0%)]\tLoss: 0.004534\n",
      "Training epoch: 33 [160/900 (18%)]\tLoss: 0.007494\n",
      "Training epoch: 33 [320/900 (35%)]\tLoss: 0.006313\n",
      "Training epoch: 33 [480/900 (53%)]\tLoss: 0.005996\n",
      "Training epoch: 33 [640/900 (70%)]\tLoss: 0.003474\n",
      "Training epoch: 33 [800/900 (88%)]\tLoss: 0.005372\n",
      "=========> Epoch: 33 Average loss: 0.0067\n",
      "Correlation coefficient: 0.7651\n",
      "⏹️  Epoch 33 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 2 best correlation: 0.7659\n",
      "\n",
      "========== Cross-validation Fold 3/10 ==========\n",
      "🔄 Fold 3: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 0.987761\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 0.798949\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 0.965412\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.984333\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.711761\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.463457\n",
      "=========> Epoch: 1 Average loss: 0.8087\n",
      "Correlation coefficient: 0.7653\n",
      "✅ Epoch 1: New best correlation = 0.7653\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.709404\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.312206\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.226372\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.195739\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.280859\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.426251\n",
      "=========> Epoch: 2 Average loss: 0.2969\n",
      "Correlation coefficient: 0.6330\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.050162\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.094519\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.072452\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.116016\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.060531\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.053483\n",
      "=========> Epoch: 3 Average loss: 0.0864\n",
      "Correlation coefficient: 0.6857\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.092467\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.095029\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.050584\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.037198\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.035520\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.048590\n",
      "=========> Epoch: 4 Average loss: 0.0495\n",
      "Correlation coefficient: 0.6887\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.020493\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.029635\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.028804\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.031531\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.063020\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.019149\n",
      "=========> Epoch: 5 Average loss: 0.0314\n",
      "Correlation coefficient: 0.6954\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.016823\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.011336\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.021438\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.023307\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.016332\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.016888\n",
      "=========> Epoch: 6 Average loss: 0.0203\n",
      "Correlation coefficient: 0.7064\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.031943\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.015228\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.013987\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.013260\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.014492\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.010879\n",
      "=========> Epoch: 7 Average loss: 0.0160\n",
      "Correlation coefficient: 0.7033\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.015983\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.016318\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.012079\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.008108\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.013661\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.010013\n",
      "=========> Epoch: 8 Average loss: 0.0116\n",
      "Correlation coefficient: 0.7115\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.005935\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.006642\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.011483\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.005386\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.008627\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.012768\n",
      "=========> Epoch: 9 Average loss: 0.0091\n",
      "Correlation coefficient: 0.7177\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.005412\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.011017\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.013026\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.006850\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.013144\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.007459\n",
      "=========> Epoch: 10 Average loss: 0.0095\n",
      "Correlation coefficient: 0.7118\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.005281\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.004963\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.011342\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.029550\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.008358\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.022812\n",
      "=========> Epoch: 11 Average loss: 0.0098\n",
      "Correlation coefficient: 0.7141\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.009644\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.005849\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.013587\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.008499\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.005534\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.004725\n",
      "=========> Epoch: 12 Average loss: 0.0078\n",
      "Correlation coefficient: 0.7191\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.004497\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.005664\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.013488\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.004738\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.009371\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.004823\n",
      "=========> Epoch: 13 Average loss: 0.0075\n",
      "Correlation coefficient: 0.7143\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.003645\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.008992\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.011840\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.010656\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.006484\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.006672\n",
      "=========> Epoch: 14 Average loss: 0.0090\n",
      "Correlation coefficient: 0.7134\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.004933\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.006118\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.010608\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.007306\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.004849\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.016316\n",
      "=========> Epoch: 15 Average loss: 0.0086\n",
      "Correlation coefficient: 0.7265\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.002432\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.016111\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.013283\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.008408\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.011144\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.012606\n",
      "=========> Epoch: 16 Average loss: 0.0110\n",
      "Correlation coefficient: 0.7189\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.009987\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.035797\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.010266\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.010400\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.006033\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.012694\n",
      "=========> Epoch: 17 Average loss: 0.0106\n",
      "Correlation coefficient: 0.7163\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.004584\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.009155\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.039107\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.012992\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.009533\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.020907\n",
      "=========> Epoch: 18 Average loss: 0.0181\n",
      "Correlation coefficient: 0.7178\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.009231\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.008313\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.017320\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.018624\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.090113\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.039786\n",
      "=========> Epoch: 19 Average loss: 0.0262\n",
      "Correlation coefficient: 0.7189\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.021585\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.041815\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.027626\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.024749\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.023645\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.030270\n",
      "=========> Epoch: 20 Average loss: 0.0403\n",
      "Correlation coefficient: 0.7171\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.038339\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.024572\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.062379\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.081974\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.014919\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.008786\n",
      "=========> Epoch: 21 Average loss: 0.0385\n",
      "Correlation coefficient: 0.7214\n",
      "⏹️  Epoch 21 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 3 best correlation: 0.7653\n",
      "\n",
      "========== Cross-validation Fold 4/10 ==========\n",
      "🔄 Fold 4: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 1.432217\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 0.716511\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 0.806240\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.889874\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.849283\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.383380\n",
      "=========> Epoch: 1 Average loss: 0.8027\n",
      "Correlation coefficient: 0.5435\n",
      "✅ Epoch 1: New best correlation = 0.5435\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.208837\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.417592\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.256815\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.338093\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.502635\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.328491\n",
      "=========> Epoch: 2 Average loss: 0.3540\n",
      "Correlation coefficient: 0.5363\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.393769\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.121408\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.061560\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.102773\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.067153\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.082479\n",
      "=========> Epoch: 3 Average loss: 0.1432\n",
      "Correlation coefficient: 0.5469\n",
      "✅ Epoch 3: New best correlation = 0.5469\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.033425\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.048764\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.050105\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.090669\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.037508\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.023233\n",
      "=========> Epoch: 4 Average loss: 0.0599\n",
      "Correlation coefficient: 0.5460\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.028938\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.029383\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.018755\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.030932\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.029447\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.021756\n",
      "=========> Epoch: 5 Average loss: 0.0325\n",
      "Correlation coefficient: 0.5545\n",
      "✅ Epoch 5: New best correlation = 0.5545\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.009984\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.024475\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.014786\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.015601\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.006817\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.006199\n",
      "=========> Epoch: 6 Average loss: 0.0160\n",
      "Correlation coefficient: 0.5458\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.003216\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.003890\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.007715\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.005957\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.004648\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.014831\n",
      "=========> Epoch: 7 Average loss: 0.0068\n",
      "Correlation coefficient: 0.5502\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.001973\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.005448\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.006799\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.007082\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.002754\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.007455\n",
      "=========> Epoch: 8 Average loss: 0.0041\n",
      "Correlation coefficient: 0.5505\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.000899\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.004545\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.002700\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.002834\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.001417\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.001276\n",
      "=========> Epoch: 9 Average loss: 0.0034\n",
      "Correlation coefficient: 0.5469\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.003603\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.003394\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.005914\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.005729\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.010209\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.001043\n",
      "=========> Epoch: 10 Average loss: 0.0057\n",
      "Correlation coefficient: 0.5443\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.004551\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.003568\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.011706\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.009802\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.007239\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.005705\n",
      "=========> Epoch: 11 Average loss: 0.0063\n",
      "Correlation coefficient: 0.5531\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.002313\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.001912\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.004640\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.005524\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.002956\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.007957\n",
      "=========> Epoch: 12 Average loss: 0.0049\n",
      "Correlation coefficient: 0.5488\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.002904\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.005552\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.004766\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.002713\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.004484\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.004510\n",
      "=========> Epoch: 13 Average loss: 0.0051\n",
      "Correlation coefficient: 0.5457\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.007976\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.003850\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.006414\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.005967\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.008019\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.002122\n",
      "=========> Epoch: 14 Average loss: 0.0052\n",
      "Correlation coefficient: 0.5489\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.002274\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.005182\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.004162\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.003325\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.005364\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.002261\n",
      "=========> Epoch: 15 Average loss: 0.0052\n",
      "Correlation coefficient: 0.5416\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.001609\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.007165\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.005183\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.008277\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.007606\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.004870\n",
      "=========> Epoch: 16 Average loss: 0.0088\n",
      "Correlation coefficient: 0.5529\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.004395\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.015245\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.008912\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.006667\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.011840\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.013608\n",
      "=========> Epoch: 17 Average loss: 0.0178\n",
      "Correlation coefficient: 0.5515\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.006103\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.033516\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.009955\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.013376\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.022351\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.021061\n",
      "=========> Epoch: 18 Average loss: 0.0170\n",
      "Correlation coefficient: 0.5596\n",
      "✅ Epoch 18: New best correlation = 0.5596\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.011249\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.008503\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.012244\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.025754\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.014764\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.021278\n",
      "=========> Epoch: 19 Average loss: 0.0153\n",
      "Correlation coefficient: 0.5481\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.008645\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.017027\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.113432\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.019088\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.028540\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.017778\n",
      "=========> Epoch: 20 Average loss: 0.0238\n",
      "Correlation coefficient: 0.5473\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.010701\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.016496\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.019280\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.069837\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.033358\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.008414\n",
      "=========> Epoch: 21 Average loss: 0.0258\n",
      "Correlation coefficient: 0.5536\n",
      "Training epoch: 22 [0/900 (0%)]\tLoss: 0.016635\n",
      "Training epoch: 22 [160/900 (18%)]\tLoss: 0.032595\n",
      "Training epoch: 22 [320/900 (35%)]\tLoss: 0.006497\n",
      "Training epoch: 22 [480/900 (53%)]\tLoss: 0.064828\n",
      "Training epoch: 22 [640/900 (70%)]\tLoss: 0.010572\n",
      "Training epoch: 22 [800/900 (88%)]\tLoss: 0.036973\n",
      "=========> Epoch: 22 Average loss: 0.0184\n",
      "Correlation coefficient: 0.5469\n",
      "Training epoch: 23 [0/900 (0%)]\tLoss: 0.011394\n",
      "Training epoch: 23 [160/900 (18%)]\tLoss: 0.017121\n",
      "Training epoch: 23 [320/900 (35%)]\tLoss: 0.016131\n",
      "Training epoch: 23 [480/900 (53%)]\tLoss: 0.011655\n",
      "Training epoch: 23 [640/900 (70%)]\tLoss: 0.007992\n",
      "Training epoch: 23 [800/900 (88%)]\tLoss: 0.023058\n",
      "=========> Epoch: 23 Average loss: 0.0238\n",
      "Correlation coefficient: 0.5474\n",
      "Training epoch: 24 [0/900 (0%)]\tLoss: 0.009653\n",
      "Training epoch: 24 [160/900 (18%)]\tLoss: 0.020297\n",
      "Training epoch: 24 [320/900 (35%)]\tLoss: 0.028073\n",
      "Training epoch: 24 [480/900 (53%)]\tLoss: 0.005103\n",
      "Training epoch: 24 [640/900 (70%)]\tLoss: 0.005541\n",
      "Training epoch: 24 [800/900 (88%)]\tLoss: 0.017381\n",
      "=========> Epoch: 24 Average loss: 0.0168\n",
      "Correlation coefficient: 0.5492\n",
      "Training epoch: 25 [0/900 (0%)]\tLoss: 0.002238\n",
      "Training epoch: 25 [160/900 (18%)]\tLoss: 0.003274\n",
      "Training epoch: 25 [320/900 (35%)]\tLoss: 0.004877\n",
      "Training epoch: 25 [480/900 (53%)]\tLoss: 0.006765\n",
      "Training epoch: 25 [640/900 (70%)]\tLoss: 0.012275\n",
      "Training epoch: 25 [800/900 (88%)]\tLoss: 0.009424\n",
      "=========> Epoch: 25 Average loss: 0.0093\n",
      "Correlation coefficient: 0.5520\n",
      "Training epoch: 26 [0/900 (0%)]\tLoss: 0.001326\n",
      "Training epoch: 26 [160/900 (18%)]\tLoss: 0.012178\n",
      "Training epoch: 26 [320/900 (35%)]\tLoss: 0.018925\n",
      "Training epoch: 26 [480/900 (53%)]\tLoss: 0.003564\n",
      "Training epoch: 26 [640/900 (70%)]\tLoss: 0.016065\n",
      "Training epoch: 26 [800/900 (88%)]\tLoss: 0.008328\n",
      "=========> Epoch: 26 Average loss: 0.0066\n",
      "Correlation coefficient: 0.5505\n",
      "Training epoch: 27 [0/900 (0%)]\tLoss: 0.003875\n",
      "Training epoch: 27 [160/900 (18%)]\tLoss: 0.005847\n",
      "Training epoch: 27 [320/900 (35%)]\tLoss: 0.005194\n",
      "Training epoch: 27 [480/900 (53%)]\tLoss: 0.005622\n",
      "Training epoch: 27 [640/900 (70%)]\tLoss: 0.004403\n",
      "Training epoch: 27 [800/900 (88%)]\tLoss: 0.004437\n",
      "=========> Epoch: 27 Average loss: 0.0067\n",
      "Correlation coefficient: 0.5588\n",
      "Training epoch: 28 [0/900 (0%)]\tLoss: 0.004906\n",
      "Training epoch: 28 [160/900 (18%)]\tLoss: 0.001994\n",
      "Training epoch: 28 [320/900 (35%)]\tLoss: 0.003791\n",
      "Training epoch: 28 [480/900 (53%)]\tLoss: 0.002776\n",
      "Training epoch: 28 [640/900 (70%)]\tLoss: 0.010112\n",
      "Training epoch: 28 [800/900 (88%)]\tLoss: 0.009703\n",
      "=========> Epoch: 28 Average loss: 0.0071\n",
      "Correlation coefficient: 0.5531\n",
      "Training epoch: 29 [0/900 (0%)]\tLoss: 0.004797\n",
      "Training epoch: 29 [160/900 (18%)]\tLoss: 0.003430\n",
      "Training epoch: 29 [320/900 (35%)]\tLoss: 0.005710\n",
      "Training epoch: 29 [480/900 (53%)]\tLoss: 0.005203\n",
      "Training epoch: 29 [640/900 (70%)]\tLoss: 0.002444\n",
      "Training epoch: 29 [800/900 (88%)]\tLoss: 0.004508\n",
      "=========> Epoch: 29 Average loss: 0.0043\n",
      "Correlation coefficient: 0.5528\n",
      "Training epoch: 30 [0/900 (0%)]\tLoss: 0.003176\n",
      "Training epoch: 30 [160/900 (18%)]\tLoss: 0.001386\n",
      "Training epoch: 30 [320/900 (35%)]\tLoss: 0.003016\n",
      "Training epoch: 30 [480/900 (53%)]\tLoss: 0.001839\n",
      "Training epoch: 30 [640/900 (70%)]\tLoss: 0.004906\n",
      "Training epoch: 30 [800/900 (88%)]\tLoss: 0.002242\n",
      "=========> Epoch: 30 Average loss: 0.0026\n",
      "Correlation coefficient: 0.5494\n",
      "Training epoch: 31 [0/900 (0%)]\tLoss: 0.000710\n",
      "Training epoch: 31 [160/900 (18%)]\tLoss: 0.001108\n",
      "Training epoch: 31 [320/900 (35%)]\tLoss: 0.001316\n",
      "Training epoch: 31 [480/900 (53%)]\tLoss: 0.002631\n",
      "Training epoch: 31 [640/900 (70%)]\tLoss: 0.001409\n",
      "Training epoch: 31 [800/900 (88%)]\tLoss: 0.002127\n",
      "=========> Epoch: 31 Average loss: 0.0020\n",
      "Correlation coefficient: 0.5528\n",
      "Training epoch: 32 [0/900 (0%)]\tLoss: 0.002270\n",
      "Training epoch: 32 [160/900 (18%)]\tLoss: 0.001318\n",
      "Training epoch: 32 [320/900 (35%)]\tLoss: 0.002089\n",
      "Training epoch: 32 [480/900 (53%)]\tLoss: 0.001158\n",
      "Training epoch: 32 [640/900 (70%)]\tLoss: 0.001020\n",
      "Training epoch: 32 [800/900 (88%)]\tLoss: 0.002265\n",
      "=========> Epoch: 32 Average loss: 0.0023\n",
      "Correlation coefficient: 0.5488\n",
      "Training epoch: 33 [0/900 (0%)]\tLoss: 0.000576\n",
      "Training epoch: 33 [160/900 (18%)]\tLoss: 0.001821\n",
      "Training epoch: 33 [320/900 (35%)]\tLoss: 0.003112\n",
      "Training epoch: 33 [480/900 (53%)]\tLoss: 0.002179\n",
      "Training epoch: 33 [640/900 (70%)]\tLoss: 0.002512\n",
      "Training epoch: 33 [800/900 (88%)]\tLoss: 0.000904\n",
      "=========> Epoch: 33 Average loss: 0.0026\n",
      "Correlation coefficient: 0.5557\n",
      "Training epoch: 34 [0/900 (0%)]\tLoss: 0.002077\n",
      "Training epoch: 34 [160/900 (18%)]\tLoss: 0.001292\n",
      "Training epoch: 34 [320/900 (35%)]\tLoss: 0.003679\n",
      "Training epoch: 34 [480/900 (53%)]\tLoss: 0.002195\n",
      "Training epoch: 34 [640/900 (70%)]\tLoss: 0.002232\n",
      "Training epoch: 34 [800/900 (88%)]\tLoss: 0.002166\n",
      "=========> Epoch: 34 Average loss: 0.0027\n",
      "Correlation coefficient: 0.5489\n",
      "Training epoch: 35 [0/900 (0%)]\tLoss: 0.001195\n",
      "Training epoch: 35 [160/900 (18%)]\tLoss: 0.007504\n",
      "Training epoch: 35 [320/900 (35%)]\tLoss: 0.001991\n",
      "Training epoch: 35 [480/900 (53%)]\tLoss: 0.001582\n",
      "Training epoch: 35 [640/900 (70%)]\tLoss: 0.005992\n",
      "Training epoch: 35 [800/900 (88%)]\tLoss: 0.003319\n",
      "=========> Epoch: 35 Average loss: 0.0041\n",
      "Correlation coefficient: 0.5517\n",
      "Training epoch: 36 [0/900 (0%)]\tLoss: 0.010084\n",
      "Training epoch: 36 [160/900 (18%)]\tLoss: 0.002862\n",
      "Training epoch: 36 [320/900 (35%)]\tLoss: 0.003533\n",
      "Training epoch: 36 [480/900 (53%)]\tLoss: 0.004348\n",
      "Training epoch: 36 [640/900 (70%)]\tLoss: 0.003505\n",
      "Training epoch: 36 [800/900 (88%)]\tLoss: 0.004196\n",
      "=========> Epoch: 36 Average loss: 0.0056\n",
      "Correlation coefficient: 0.5525\n",
      "Training epoch: 37 [0/900 (0%)]\tLoss: 0.002565\n",
      "Training epoch: 37 [160/900 (18%)]\tLoss: 0.003465\n",
      "Training epoch: 37 [320/900 (35%)]\tLoss: 0.012561\n",
      "Training epoch: 37 [480/900 (53%)]\tLoss: 0.005208\n",
      "Training epoch: 37 [640/900 (70%)]\tLoss: 0.009943\n",
      "Training epoch: 37 [800/900 (88%)]\tLoss: 0.006228\n",
      "=========> Epoch: 37 Average loss: 0.0066\n",
      "Correlation coefficient: 0.5515\n",
      "Training epoch: 38 [0/900 (0%)]\tLoss: 0.005075\n",
      "Training epoch: 38 [160/900 (18%)]\tLoss: 0.006851\n",
      "Training epoch: 38 [320/900 (35%)]\tLoss: 0.003003\n",
      "Training epoch: 38 [480/900 (53%)]\tLoss: 0.005241\n",
      "Training epoch: 38 [640/900 (70%)]\tLoss: 0.033055\n",
      "Training epoch: 38 [800/900 (88%)]\tLoss: 0.007083\n",
      "=========> Epoch: 38 Average loss: 0.0059\n",
      "Correlation coefficient: 0.5454\n",
      "⏹️  Epoch 38 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 4 best correlation: 0.5596\n",
      "\n",
      "========== Cross-validation Fold 5/10 ==========\n",
      "🔄 Fold 5: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 1.102215\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 1.039254\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 1.362041\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 1.128354\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.532327\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.548537\n",
      "=========> Epoch: 1 Average loss: 0.8830\n",
      "Correlation coefficient: 0.6516\n",
      "✅ Epoch 1: New best correlation = 0.6516\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.318756\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.355041\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.780658\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.426363\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.523162\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.351862\n",
      "=========> Epoch: 2 Average loss: 0.4079\n",
      "Correlation coefficient: 0.7244\n",
      "✅ Epoch 2: New best correlation = 0.7244\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.111743\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.111135\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.155635\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.099394\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.109480\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.083264\n",
      "=========> Epoch: 3 Average loss: 0.1084\n",
      "Correlation coefficient: 0.7102\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.039815\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.018433\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.063405\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.034012\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.029012\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.055098\n",
      "=========> Epoch: 4 Average loss: 0.0492\n",
      "Correlation coefficient: 0.7079\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.024290\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.019354\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.028743\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.033959\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.011399\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.018436\n",
      "=========> Epoch: 5 Average loss: 0.0227\n",
      "Correlation coefficient: 0.7174\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.014130\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.009545\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.018021\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.017199\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.013875\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.012460\n",
      "=========> Epoch: 6 Average loss: 0.0152\n",
      "Correlation coefficient: 0.7114\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.011296\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.057600\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.008366\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.006210\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.011582\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.003563\n",
      "=========> Epoch: 7 Average loss: 0.0112\n",
      "Correlation coefficient: 0.7141\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.002426\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.006017\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.010725\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.011595\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.009183\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.019520\n",
      "=========> Epoch: 8 Average loss: 0.0091\n",
      "Correlation coefficient: 0.7133\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.008799\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.011096\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.014577\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.009443\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.003860\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.006091\n",
      "=========> Epoch: 9 Average loss: 0.0101\n",
      "Correlation coefficient: 0.7142\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.004809\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.006444\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.007773\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.032295\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.008372\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.013169\n",
      "=========> Epoch: 10 Average loss: 0.0095\n",
      "Correlation coefficient: 0.7147\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.011560\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.014386\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.006403\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.005283\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.009273\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.010651\n",
      "=========> Epoch: 11 Average loss: 0.0108\n",
      "Correlation coefficient: 0.7191\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.012310\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.007477\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.021771\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.011680\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.005183\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.016606\n",
      "=========> Epoch: 12 Average loss: 0.0122\n",
      "Correlation coefficient: 0.7184\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.010252\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.011664\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.003321\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.007863\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.008700\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.006528\n",
      "=========> Epoch: 13 Average loss: 0.0120\n",
      "Correlation coefficient: 0.7162\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.003877\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.004600\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.021542\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.016205\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.015141\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.021403\n",
      "=========> Epoch: 14 Average loss: 0.0122\n",
      "Correlation coefficient: 0.7129\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.007363\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.019965\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.012319\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.010451\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.026788\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.017725\n",
      "=========> Epoch: 15 Average loss: 0.0169\n",
      "Correlation coefficient: 0.7112\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.015465\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.067571\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.084982\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.017783\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.016638\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.021750\n",
      "=========> Epoch: 16 Average loss: 0.0274\n",
      "Correlation coefficient: 0.7074\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.020446\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.045515\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.093895\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.016598\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.038395\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.014386\n",
      "=========> Epoch: 17 Average loss: 0.0316\n",
      "Correlation coefficient: 0.7188\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.027050\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.014695\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.012046\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.012416\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.026451\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.005179\n",
      "=========> Epoch: 18 Average loss: 0.0175\n",
      "Correlation coefficient: 0.7142\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.006402\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.034260\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.013012\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.015767\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.006489\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.005744\n",
      "=========> Epoch: 19 Average loss: 0.0137\n",
      "Correlation coefficient: 0.7177\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.003501\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.004945\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.008039\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.015229\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.004279\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.008511\n",
      "=========> Epoch: 20 Average loss: 0.0098\n",
      "Correlation coefficient: 0.7211\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.006743\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.008586\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.023625\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.003256\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.008467\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.007525\n",
      "=========> Epoch: 21 Average loss: 0.0109\n",
      "Correlation coefficient: 0.7124\n",
      "Training epoch: 22 [0/900 (0%)]\tLoss: 0.010824\n",
      "Training epoch: 22 [160/900 (18%)]\tLoss: 0.011366\n",
      "Training epoch: 22 [320/900 (35%)]\tLoss: 0.012321\n",
      "Training epoch: 22 [480/900 (53%)]\tLoss: 0.016541\n",
      "Training epoch: 22 [640/900 (70%)]\tLoss: 0.012882\n",
      "Training epoch: 22 [800/900 (88%)]\tLoss: 0.008082\n",
      "=========> Epoch: 22 Average loss: 0.0104\n",
      "Correlation coefficient: 0.7253\n",
      "✅ Epoch 22: New best correlation = 0.7253\n",
      "Training epoch: 23 [0/900 (0%)]\tLoss: 0.009010\n",
      "Training epoch: 23 [160/900 (18%)]\tLoss: 0.018366\n",
      "Training epoch: 23 [320/900 (35%)]\tLoss: 0.005294\n",
      "Training epoch: 23 [480/900 (53%)]\tLoss: 0.013007\n",
      "Training epoch: 23 [640/900 (70%)]\tLoss: 0.004814\n",
      "Training epoch: 23 [800/900 (88%)]\tLoss: 0.005482\n",
      "=========> Epoch: 23 Average loss: 0.0089\n",
      "Correlation coefficient: 0.7191\n",
      "Training epoch: 24 [0/900 (0%)]\tLoss: 0.011794\n",
      "Training epoch: 24 [160/900 (18%)]\tLoss: 0.008415\n",
      "Training epoch: 24 [320/900 (35%)]\tLoss: 0.005234\n",
      "Training epoch: 24 [480/900 (53%)]\tLoss: 0.006363\n",
      "Training epoch: 24 [640/900 (70%)]\tLoss: 0.013246\n",
      "Training epoch: 24 [800/900 (88%)]\tLoss: 0.020368\n",
      "=========> Epoch: 24 Average loss: 0.0089\n",
      "Correlation coefficient: 0.7219\n",
      "Training epoch: 25 [0/900 (0%)]\tLoss: 0.008434\n",
      "Training epoch: 25 [160/900 (18%)]\tLoss: 0.006836\n",
      "Training epoch: 25 [320/900 (35%)]\tLoss: 0.004000\n",
      "Training epoch: 25 [480/900 (53%)]\tLoss: 0.012952\n",
      "Training epoch: 25 [640/900 (70%)]\tLoss: 0.003656\n",
      "Training epoch: 25 [800/900 (88%)]\tLoss: 0.013042\n",
      "=========> Epoch: 25 Average loss: 0.0085\n",
      "Correlation coefficient: 0.7183\n",
      "Training epoch: 26 [0/900 (0%)]\tLoss: 0.006291\n",
      "Training epoch: 26 [160/900 (18%)]\tLoss: 0.017782\n",
      "Training epoch: 26 [320/900 (35%)]\tLoss: 0.008665\n",
      "Training epoch: 26 [480/900 (53%)]\tLoss: 0.017760\n",
      "Training epoch: 26 [640/900 (70%)]\tLoss: 0.009358\n",
      "Training epoch: 26 [800/900 (88%)]\tLoss: 0.009117\n",
      "=========> Epoch: 26 Average loss: 0.0082\n",
      "Correlation coefficient: 0.7255\n",
      "✅ Epoch 26: New best correlation = 0.7255\n",
      "Training epoch: 27 [0/900 (0%)]\tLoss: 0.005069\n",
      "Training epoch: 27 [160/900 (18%)]\tLoss: 0.005526\n",
      "Training epoch: 27 [320/900 (35%)]\tLoss: 0.003466\n",
      "Training epoch: 27 [480/900 (53%)]\tLoss: 0.003761\n",
      "Training epoch: 27 [640/900 (70%)]\tLoss: 0.003829\n",
      "Training epoch: 27 [800/900 (88%)]\tLoss: 0.005488\n",
      "=========> Epoch: 27 Average loss: 0.0052\n",
      "Correlation coefficient: 0.7202\n",
      "Training epoch: 28 [0/900 (0%)]\tLoss: 0.002595\n",
      "Training epoch: 28 [160/900 (18%)]\tLoss: 0.009255\n",
      "Training epoch: 28 [320/900 (35%)]\tLoss: 0.002728\n",
      "Training epoch: 28 [480/900 (53%)]\tLoss: 0.007439\n",
      "Training epoch: 28 [640/900 (70%)]\tLoss: 0.003325\n",
      "Training epoch: 28 [800/900 (88%)]\tLoss: 0.002885\n",
      "=========> Epoch: 28 Average loss: 0.0054\n",
      "Correlation coefficient: 0.7214\n",
      "Training epoch: 29 [0/900 (0%)]\tLoss: 0.001054\n",
      "Training epoch: 29 [160/900 (18%)]\tLoss: 0.004319\n",
      "Training epoch: 29 [320/900 (35%)]\tLoss: 0.005177\n",
      "Training epoch: 29 [480/900 (53%)]\tLoss: 0.006604\n",
      "Training epoch: 29 [640/900 (70%)]\tLoss: 0.001710\n",
      "Training epoch: 29 [800/900 (88%)]\tLoss: 0.005106\n",
      "=========> Epoch: 29 Average loss: 0.0057\n",
      "Correlation coefficient: 0.7169\n",
      "Training epoch: 30 [0/900 (0%)]\tLoss: 0.006195\n",
      "Training epoch: 30 [160/900 (18%)]\tLoss: 0.001232\n",
      "Training epoch: 30 [320/900 (35%)]\tLoss: 0.006093\n",
      "Training epoch: 30 [480/900 (53%)]\tLoss: 0.006776\n",
      "Training epoch: 30 [640/900 (70%)]\tLoss: 0.003698\n",
      "Training epoch: 30 [800/900 (88%)]\tLoss: 0.003169\n",
      "=========> Epoch: 30 Average loss: 0.0050\n",
      "Correlation coefficient: 0.7222\n",
      "Training epoch: 31 [0/900 (0%)]\tLoss: 0.006362\n",
      "Training epoch: 31 [160/900 (18%)]\tLoss: 0.003976\n",
      "Training epoch: 31 [320/900 (35%)]\tLoss: 0.002772\n",
      "Training epoch: 31 [480/900 (53%)]\tLoss: 0.002229\n",
      "Training epoch: 31 [640/900 (70%)]\tLoss: 0.011962\n",
      "Training epoch: 31 [800/900 (88%)]\tLoss: 0.005430\n",
      "=========> Epoch: 31 Average loss: 0.0047\n",
      "Correlation coefficient: 0.7217\n",
      "Training epoch: 32 [0/900 (0%)]\tLoss: 0.006890\n",
      "Training epoch: 32 [160/900 (18%)]\tLoss: 0.003475\n",
      "Training epoch: 32 [320/900 (35%)]\tLoss: 0.001437\n",
      "Training epoch: 32 [480/900 (53%)]\tLoss: 0.004246\n",
      "Training epoch: 32 [640/900 (70%)]\tLoss: 0.008828\n",
      "Training epoch: 32 [800/900 (88%)]\tLoss: 0.004517\n",
      "=========> Epoch: 32 Average loss: 0.0053\n",
      "Correlation coefficient: 0.7188\n",
      "Training epoch: 33 [0/900 (0%)]\tLoss: 0.003706\n",
      "Training epoch: 33 [160/900 (18%)]\tLoss: 0.007443\n",
      "Training epoch: 33 [320/900 (35%)]\tLoss: 0.002069\n",
      "Training epoch: 33 [480/900 (53%)]\tLoss: 0.002952\n",
      "Training epoch: 33 [640/900 (70%)]\tLoss: 0.002938\n",
      "Training epoch: 33 [800/900 (88%)]\tLoss: 0.002234\n",
      "=========> Epoch: 33 Average loss: 0.0059\n",
      "Correlation coefficient: 0.7195\n",
      "Training epoch: 34 [0/900 (0%)]\tLoss: 0.011023\n",
      "Training epoch: 34 [160/900 (18%)]\tLoss: 0.011016\n",
      "Training epoch: 34 [320/900 (35%)]\tLoss: 0.002547\n",
      "Training epoch: 34 [480/900 (53%)]\tLoss: 0.005304\n",
      "Training epoch: 34 [640/900 (70%)]\tLoss: 0.008780\n",
      "Training epoch: 34 [800/900 (88%)]\tLoss: 0.003667\n",
      "=========> Epoch: 34 Average loss: 0.0090\n",
      "Correlation coefficient: 0.7249\n",
      "Training epoch: 35 [0/900 (0%)]\tLoss: 0.008238\n",
      "Training epoch: 35 [160/900 (18%)]\tLoss: 0.011613\n",
      "Training epoch: 35 [320/900 (35%)]\tLoss: 0.007767\n",
      "Training epoch: 35 [480/900 (53%)]\tLoss: 0.021266\n",
      "Training epoch: 35 [640/900 (70%)]\tLoss: 0.017183\n",
      "Training epoch: 35 [800/900 (88%)]\tLoss: 0.032190\n",
      "=========> Epoch: 35 Average loss: 0.0159\n",
      "Correlation coefficient: 0.7180\n",
      "Training epoch: 36 [0/900 (0%)]\tLoss: 0.006536\n",
      "Training epoch: 36 [160/900 (18%)]\tLoss: 0.027682\n",
      "Training epoch: 36 [320/900 (35%)]\tLoss: 0.015859\n",
      "Training epoch: 36 [480/900 (53%)]\tLoss: 0.006230\n",
      "Training epoch: 36 [640/900 (70%)]\tLoss: 0.025355\n",
      "Training epoch: 36 [800/900 (88%)]\tLoss: 0.018927\n",
      "=========> Epoch: 36 Average loss: 0.0192\n",
      "Correlation coefficient: 0.7275\n",
      "✅ Epoch 36: New best correlation = 0.7275\n",
      "Training epoch: 37 [0/900 (0%)]\tLoss: 0.034971\n",
      "Training epoch: 37 [160/900 (18%)]\tLoss: 0.034854\n",
      "Training epoch: 37 [320/900 (35%)]\tLoss: 0.065920\n",
      "Training epoch: 37 [480/900 (53%)]\tLoss: 0.004549\n",
      "Training epoch: 37 [640/900 (70%)]\tLoss: 0.048189\n",
      "Training epoch: 37 [800/900 (88%)]\tLoss: 0.017213\n",
      "=========> Epoch: 37 Average loss: 0.0275\n",
      "Correlation coefficient: 0.7118\n",
      "Training epoch: 38 [0/900 (0%)]\tLoss: 0.025691\n",
      "Training epoch: 38 [160/900 (18%)]\tLoss: 0.025931\n",
      "Training epoch: 38 [320/900 (35%)]\tLoss: 0.040293\n",
      "Training epoch: 38 [480/900 (53%)]\tLoss: 0.046611\n",
      "Training epoch: 38 [640/900 (70%)]\tLoss: 0.026412\n",
      "Training epoch: 38 [800/900 (88%)]\tLoss: 0.032186\n",
      "=========> Epoch: 38 Average loss: 0.0339\n",
      "Correlation coefficient: 0.7148\n",
      "Training epoch: 39 [0/900 (0%)]\tLoss: 0.045061\n",
      "Training epoch: 39 [160/900 (18%)]\tLoss: 0.185466\n",
      "Training epoch: 39 [320/900 (35%)]\tLoss: 0.012547\n",
      "Training epoch: 39 [480/900 (53%)]\tLoss: 0.008530\n",
      "Training epoch: 39 [640/900 (70%)]\tLoss: 0.008749\n",
      "Training epoch: 39 [800/900 (88%)]\tLoss: 0.032271\n",
      "=========> Epoch: 39 Average loss: 0.0374\n",
      "Correlation coefficient: 0.7234\n",
      "Training epoch: 40 [0/900 (0%)]\tLoss: 0.017258\n",
      "Training epoch: 40 [160/900 (18%)]\tLoss: 0.032473\n",
      "Training epoch: 40 [320/900 (35%)]\tLoss: 0.050046\n",
      "Training epoch: 40 [480/900 (53%)]\tLoss: 0.037083\n",
      "Training epoch: 40 [640/900 (70%)]\tLoss: 0.035503\n",
      "Training epoch: 40 [800/900 (88%)]\tLoss: 0.024881\n",
      "=========> Epoch: 40 Average loss: 0.0321\n",
      "Correlation coefficient: 0.7054\n",
      "Training epoch: 41 [0/900 (0%)]\tLoss: 0.023517\n",
      "Training epoch: 41 [160/900 (18%)]\tLoss: 0.019616\n",
      "Training epoch: 41 [320/900 (35%)]\tLoss: 0.014324\n",
      "Training epoch: 41 [480/900 (53%)]\tLoss: 0.010027\n",
      "Training epoch: 41 [640/900 (70%)]\tLoss: 0.011740\n",
      "Training epoch: 41 [800/900 (88%)]\tLoss: 0.008329\n",
      "=========> Epoch: 41 Average loss: 0.0190\n",
      "Correlation coefficient: 0.7196\n",
      "Training epoch: 42 [0/900 (0%)]\tLoss: 0.007595\n",
      "Training epoch: 42 [160/900 (18%)]\tLoss: 0.012720\n",
      "Training epoch: 42 [320/900 (35%)]\tLoss: 0.021330\n",
      "Training epoch: 42 [480/900 (53%)]\tLoss: 0.005506\n",
      "Training epoch: 42 [640/900 (70%)]\tLoss: 0.010859\n",
      "Training epoch: 42 [800/900 (88%)]\tLoss: 0.008173\n",
      "=========> Epoch: 42 Average loss: 0.0143\n",
      "Correlation coefficient: 0.7157\n",
      "Training epoch: 43 [0/900 (0%)]\tLoss: 0.011489\n",
      "Training epoch: 43 [160/900 (18%)]\tLoss: 0.036075\n",
      "Training epoch: 43 [320/900 (35%)]\tLoss: 0.007980\n",
      "Training epoch: 43 [480/900 (53%)]\tLoss: 0.007636\n",
      "Training epoch: 43 [640/900 (70%)]\tLoss: 0.012028\n",
      "Training epoch: 43 [800/900 (88%)]\tLoss: 0.007521\n",
      "=========> Epoch: 43 Average loss: 0.0123\n",
      "Correlation coefficient: 0.7135\n",
      "Training epoch: 44 [0/900 (0%)]\tLoss: 0.005872\n",
      "Training epoch: 44 [160/900 (18%)]\tLoss: 0.007408\n",
      "Training epoch: 44 [320/900 (35%)]\tLoss: 0.006523\n",
      "Training epoch: 44 [480/900 (53%)]\tLoss: 0.007836\n",
      "Training epoch: 44 [640/900 (70%)]\tLoss: 0.003222\n",
      "Training epoch: 44 [800/900 (88%)]\tLoss: 0.002276\n",
      "=========> Epoch: 44 Average loss: 0.0054\n",
      "Correlation coefficient: 0.7166\n",
      "Training epoch: 45 [0/900 (0%)]\tLoss: 0.002097\n",
      "Training epoch: 45 [160/900 (18%)]\tLoss: 0.004556\n",
      "Training epoch: 45 [320/900 (35%)]\tLoss: 0.002590\n",
      "Training epoch: 45 [480/900 (53%)]\tLoss: 0.001332\n",
      "Training epoch: 45 [640/900 (70%)]\tLoss: 0.003818\n",
      "Training epoch: 45 [800/900 (88%)]\tLoss: 0.001316\n",
      "=========> Epoch: 45 Average loss: 0.0036\n",
      "Correlation coefficient: 0.7207\n",
      "Training epoch: 46 [0/900 (0%)]\tLoss: 0.005640\n",
      "Training epoch: 46 [160/900 (18%)]\tLoss: 0.001998\n",
      "Training epoch: 46 [320/900 (35%)]\tLoss: 0.002030\n",
      "Training epoch: 46 [480/900 (53%)]\tLoss: 0.001241\n",
      "Training epoch: 46 [640/900 (70%)]\tLoss: 0.001709\n",
      "Training epoch: 46 [800/900 (88%)]\tLoss: 0.002767\n",
      "=========> Epoch: 46 Average loss: 0.0027\n",
      "Correlation coefficient: 0.7207\n",
      "Training epoch: 47 [0/900 (0%)]\tLoss: 0.001242\n",
      "Training epoch: 47 [160/900 (18%)]\tLoss: 0.001152\n",
      "Training epoch: 47 [320/900 (35%)]\tLoss: 0.001631\n",
      "Training epoch: 47 [480/900 (53%)]\tLoss: 0.002017\n",
      "Training epoch: 47 [640/900 (70%)]\tLoss: 0.001826\n",
      "Training epoch: 47 [800/900 (88%)]\tLoss: 0.001329\n",
      "=========> Epoch: 47 Average loss: 0.0019\n",
      "Correlation coefficient: 0.7192\n",
      "Training epoch: 48 [0/900 (0%)]\tLoss: 0.001152\n",
      "Training epoch: 48 [160/900 (18%)]\tLoss: 0.003939\n",
      "Training epoch: 48 [320/900 (35%)]\tLoss: 0.001258\n",
      "Training epoch: 48 [480/900 (53%)]\tLoss: 0.000821\n",
      "Training epoch: 48 [640/900 (70%)]\tLoss: 0.000805\n",
      "Training epoch: 48 [800/900 (88%)]\tLoss: 0.000785\n",
      "=========> Epoch: 48 Average loss: 0.0009\n",
      "Correlation coefficient: 0.7189\n",
      "Training epoch: 49 [0/900 (0%)]\tLoss: 0.000363\n",
      "Training epoch: 49 [160/900 (18%)]\tLoss: 0.001159\n",
      "Training epoch: 49 [320/900 (35%)]\tLoss: 0.000992\n",
      "Training epoch: 49 [480/900 (53%)]\tLoss: 0.000525\n",
      "Training epoch: 49 [640/900 (70%)]\tLoss: 0.000969\n",
      "Training epoch: 49 [800/900 (88%)]\tLoss: 0.000239\n",
      "=========> Epoch: 49 Average loss: 0.0007\n",
      "Correlation coefficient: 0.7211\n",
      "Training epoch: 50 [0/900 (0%)]\tLoss: 0.001585\n",
      "Training epoch: 50 [160/900 (18%)]\tLoss: 0.000473\n",
      "Training epoch: 50 [320/900 (35%)]\tLoss: 0.000546\n",
      "Training epoch: 50 [480/900 (53%)]\tLoss: 0.000919\n",
      "Training epoch: 50 [640/900 (70%)]\tLoss: 0.000485\n",
      "Training epoch: 50 [800/900 (88%)]\tLoss: 0.000754\n",
      "=========> Epoch: 50 Average loss: 0.0009\n",
      "Correlation coefficient: 0.7180\n",
      "Training epoch: 51 [0/900 (0%)]\tLoss: 0.000899\n",
      "Training epoch: 51 [160/900 (18%)]\tLoss: 0.000457\n",
      "Training epoch: 51 [320/900 (35%)]\tLoss: 0.001791\n",
      "Training epoch: 51 [480/900 (53%)]\tLoss: 0.001717\n",
      "Training epoch: 51 [640/900 (70%)]\tLoss: 0.000696\n",
      "Training epoch: 51 [800/900 (88%)]\tLoss: 0.000401\n",
      "=========> Epoch: 51 Average loss: 0.0010\n",
      "Correlation coefficient: 0.7217\n",
      "Training epoch: 52 [0/900 (0%)]\tLoss: 0.000635\n",
      "Training epoch: 52 [160/900 (18%)]\tLoss: 0.000993\n",
      "Training epoch: 52 [320/900 (35%)]\tLoss: 0.001937\n",
      "Training epoch: 52 [480/900 (53%)]\tLoss: 0.001076\n",
      "Training epoch: 52 [640/900 (70%)]\tLoss: 0.001579\n",
      "Training epoch: 52 [800/900 (88%)]\tLoss: 0.001422\n",
      "=========> Epoch: 52 Average loss: 0.0011\n",
      "Correlation coefficient: 0.7183\n",
      "Training epoch: 53 [0/900 (0%)]\tLoss: 0.000610\n",
      "Training epoch: 53 [160/900 (18%)]\tLoss: 0.000681\n",
      "Training epoch: 53 [320/900 (35%)]\tLoss: 0.000759\n",
      "Training epoch: 53 [480/900 (53%)]\tLoss: 0.000690\n",
      "Training epoch: 53 [640/900 (70%)]\tLoss: 0.002646\n",
      "Training epoch: 53 [800/900 (88%)]\tLoss: 0.001571\n",
      "=========> Epoch: 53 Average loss: 0.0012\n",
      "Correlation coefficient: 0.7215\n",
      "Training epoch: 54 [0/900 (0%)]\tLoss: 0.000662\n",
      "Training epoch: 54 [160/900 (18%)]\tLoss: 0.001121\n",
      "Training epoch: 54 [320/900 (35%)]\tLoss: 0.000719\n",
      "Training epoch: 54 [480/900 (53%)]\tLoss: 0.001465\n",
      "Training epoch: 54 [640/900 (70%)]\tLoss: 0.001406\n",
      "Training epoch: 54 [800/900 (88%)]\tLoss: 0.000542\n",
      "=========> Epoch: 54 Average loss: 0.0013\n",
      "Correlation coefficient: 0.7218\n",
      "Training epoch: 55 [0/900 (0%)]\tLoss: 0.001096\n",
      "Training epoch: 55 [160/900 (18%)]\tLoss: 0.000579\n",
      "Training epoch: 55 [320/900 (35%)]\tLoss: 0.000952\n",
      "Training epoch: 55 [480/900 (53%)]\tLoss: 0.001107\n",
      "Training epoch: 55 [640/900 (70%)]\tLoss: 0.000569\n",
      "Training epoch: 55 [800/900 (88%)]\tLoss: 0.006885\n",
      "=========> Epoch: 55 Average loss: 0.0027\n",
      "Correlation coefficient: 0.7207\n",
      "Training epoch: 56 [0/900 (0%)]\tLoss: 0.001509\n",
      "Training epoch: 56 [160/900 (18%)]\tLoss: 0.005581\n",
      "Training epoch: 56 [320/900 (35%)]\tLoss: 0.004896\n",
      "Training epoch: 56 [480/900 (53%)]\tLoss: 0.005342\n",
      "Training epoch: 56 [640/900 (70%)]\tLoss: 0.003170\n",
      "Training epoch: 56 [800/900 (88%)]\tLoss: 0.003895\n",
      "=========> Epoch: 56 Average loss: 0.0040\n",
      "Correlation coefficient: 0.7218\n",
      "⏹️  Epoch 56 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 5 best correlation: 0.7275\n",
      "\n",
      "========== Cross-validation Fold 6/10 ==========\n",
      "🔄 Fold 6: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 1.653369\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 0.577985\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 1.048363\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.434971\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.383274\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.869216\n",
      "=========> Epoch: 1 Average loss: 0.8773\n",
      "Correlation coefficient: 0.6598\n",
      "✅ Epoch 1: New best correlation = 0.6598\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.512008\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.595722\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.401057\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.549299\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.404756\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.342494\n",
      "=========> Epoch: 2 Average loss: 0.4146\n",
      "Correlation coefficient: 0.6950\n",
      "✅ Epoch 2: New best correlation = 0.6950\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.120822\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.300222\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.178515\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.274049\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.132840\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.044399\n",
      "=========> Epoch: 3 Average loss: 0.1435\n",
      "Correlation coefficient: 0.6795\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.053790\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.082697\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.126672\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.043014\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.038108\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.033604\n",
      "=========> Epoch: 4 Average loss: 0.0594\n",
      "Correlation coefficient: 0.6899\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.008891\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.034299\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.013539\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.034501\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.010590\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.020935\n",
      "=========> Epoch: 5 Average loss: 0.0239\n",
      "Correlation coefficient: 0.7017\n",
      "✅ Epoch 5: New best correlation = 0.7017\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.007625\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.010365\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.006560\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.015802\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.011304\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.006929\n",
      "=========> Epoch: 6 Average loss: 0.0127\n",
      "Correlation coefficient: 0.6937\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.008973\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.004945\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.005137\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.012141\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.020641\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.002335\n",
      "=========> Epoch: 7 Average loss: 0.0071\n",
      "Correlation coefficient: 0.6932\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.002943\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.005482\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.007226\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.002677\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.006934\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.003262\n",
      "=========> Epoch: 8 Average loss: 0.0048\n",
      "Correlation coefficient: 0.6994\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.002322\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.004046\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.001998\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.002817\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.004883\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.003995\n",
      "=========> Epoch: 9 Average loss: 0.0042\n",
      "Correlation coefficient: 0.6954\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.001367\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.005273\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.004148\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.012135\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.005012\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.007817\n",
      "=========> Epoch: 10 Average loss: 0.0051\n",
      "Correlation coefficient: 0.7027\n",
      "✅ Epoch 10: New best correlation = 0.7027\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.006849\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.004567\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.006035\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.008292\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.008765\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.006035\n",
      "=========> Epoch: 11 Average loss: 0.0065\n",
      "Correlation coefficient: 0.6956\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.008195\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.006365\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.010147\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.007479\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.005513\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.005379\n",
      "=========> Epoch: 12 Average loss: 0.0087\n",
      "Correlation coefficient: 0.6963\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.004960\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.021635\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.013291\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.015699\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.006547\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.012912\n",
      "=========> Epoch: 13 Average loss: 0.0158\n",
      "Correlation coefficient: 0.6939\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.019345\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.040537\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.014457\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.011729\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.025633\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.018957\n",
      "=========> Epoch: 14 Average loss: 0.0236\n",
      "Correlation coefficient: 0.7011\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.013283\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.044379\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.008425\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.014935\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.027791\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.006832\n",
      "=========> Epoch: 15 Average loss: 0.0168\n",
      "Correlation coefficient: 0.6988\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.018998\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.018802\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.013552\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.007772\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.021152\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.008498\n",
      "=========> Epoch: 16 Average loss: 0.0152\n",
      "Correlation coefficient: 0.6946\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.013182\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.009150\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.003892\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.011922\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.021184\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.015133\n",
      "=========> Epoch: 17 Average loss: 0.0167\n",
      "Correlation coefficient: 0.6885\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.025957\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.007773\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.007686\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.010484\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.014477\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.007855\n",
      "=========> Epoch: 18 Average loss: 0.0135\n",
      "Correlation coefficient: 0.6988\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.010401\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.004931\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.012398\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.010650\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.007225\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.020107\n",
      "=========> Epoch: 19 Average loss: 0.0111\n",
      "Correlation coefficient: 0.7036\n",
      "✅ Epoch 19: New best correlation = 0.7036\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.007424\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.003529\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.003913\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.012188\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.006036\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.007543\n",
      "=========> Epoch: 20 Average loss: 0.0086\n",
      "Correlation coefficient: 0.7038\n",
      "✅ Epoch 20: New best correlation = 0.7038\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.007333\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.003093\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.006802\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.009929\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.007321\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.012220\n",
      "=========> Epoch: 21 Average loss: 0.0068\n",
      "Correlation coefficient: 0.6992\n",
      "Training epoch: 22 [0/900 (0%)]\tLoss: 0.013391\n",
      "Training epoch: 22 [160/900 (18%)]\tLoss: 0.002591\n",
      "Training epoch: 22 [320/900 (35%)]\tLoss: 0.006997\n",
      "Training epoch: 22 [480/900 (53%)]\tLoss: 0.005768\n",
      "Training epoch: 22 [640/900 (70%)]\tLoss: 0.003671\n",
      "Training epoch: 22 [800/900 (88%)]\tLoss: 0.002456\n",
      "=========> Epoch: 22 Average loss: 0.0057\n",
      "Correlation coefficient: 0.7019\n",
      "Training epoch: 23 [0/900 (0%)]\tLoss: 0.002790\n",
      "Training epoch: 23 [160/900 (18%)]\tLoss: 0.014797\n",
      "Training epoch: 23 [320/900 (35%)]\tLoss: 0.005872\n",
      "Training epoch: 23 [480/900 (53%)]\tLoss: 0.007531\n",
      "Training epoch: 23 [640/900 (70%)]\tLoss: 0.006038\n",
      "Training epoch: 23 [800/900 (88%)]\tLoss: 0.002570\n",
      "=========> Epoch: 23 Average loss: 0.0062\n",
      "Correlation coefficient: 0.7031\n",
      "Training epoch: 24 [0/900 (0%)]\tLoss: 0.003039\n",
      "Training epoch: 24 [160/900 (18%)]\tLoss: 0.005617\n",
      "Training epoch: 24 [320/900 (35%)]\tLoss: 0.012357\n",
      "Training epoch: 24 [480/900 (53%)]\tLoss: 0.005403\n",
      "Training epoch: 24 [640/900 (70%)]\tLoss: 0.008659\n",
      "Training epoch: 24 [800/900 (88%)]\tLoss: 0.007076\n",
      "=========> Epoch: 24 Average loss: 0.0075\n",
      "Correlation coefficient: 0.6987\n",
      "Training epoch: 25 [0/900 (0%)]\tLoss: 0.002776\n",
      "Training epoch: 25 [160/900 (18%)]\tLoss: 0.005248\n",
      "Training epoch: 25 [320/900 (35%)]\tLoss: 0.007932\n",
      "Training epoch: 25 [480/900 (53%)]\tLoss: 0.003578\n",
      "Training epoch: 25 [640/900 (70%)]\tLoss: 0.004590\n",
      "Training epoch: 25 [800/900 (88%)]\tLoss: 0.010197\n",
      "=========> Epoch: 25 Average loss: 0.0062\n",
      "Correlation coefficient: 0.7030\n",
      "Training epoch: 26 [0/900 (0%)]\tLoss: 0.004494\n",
      "Training epoch: 26 [160/900 (18%)]\tLoss: 0.001727\n",
      "Training epoch: 26 [320/900 (35%)]\tLoss: 0.007091\n",
      "Training epoch: 26 [480/900 (53%)]\tLoss: 0.006362\n",
      "Training epoch: 26 [640/900 (70%)]\tLoss: 0.003455\n",
      "Training epoch: 26 [800/900 (88%)]\tLoss: 0.004623\n",
      "=========> Epoch: 26 Average loss: 0.0056\n",
      "Correlation coefficient: 0.7010\n",
      "Training epoch: 27 [0/900 (0%)]\tLoss: 0.002856\n",
      "Training epoch: 27 [160/900 (18%)]\tLoss: 0.005422\n",
      "Training epoch: 27 [320/900 (35%)]\tLoss: 0.001893\n",
      "Training epoch: 27 [480/900 (53%)]\tLoss: 0.016647\n",
      "Training epoch: 27 [640/900 (70%)]\tLoss: 0.005712\n",
      "Training epoch: 27 [800/900 (88%)]\tLoss: 0.007458\n",
      "=========> Epoch: 27 Average loss: 0.0062\n",
      "Correlation coefficient: 0.7024\n",
      "Training epoch: 28 [0/900 (0%)]\tLoss: 0.004231\n",
      "Training epoch: 28 [160/900 (18%)]\tLoss: 0.013692\n",
      "Training epoch: 28 [320/900 (35%)]\tLoss: 0.011365\n",
      "Training epoch: 28 [480/900 (53%)]\tLoss: 0.008571\n",
      "Training epoch: 28 [640/900 (70%)]\tLoss: 0.010827\n",
      "Training epoch: 28 [800/900 (88%)]\tLoss: 0.012350\n",
      "=========> Epoch: 28 Average loss: 0.0094\n",
      "Correlation coefficient: 0.7068\n",
      "✅ Epoch 28: New best correlation = 0.7068\n",
      "Training epoch: 29 [0/900 (0%)]\tLoss: 0.004947\n",
      "Training epoch: 29 [160/900 (18%)]\tLoss: 0.004987\n",
      "Training epoch: 29 [320/900 (35%)]\tLoss: 0.013308\n",
      "Training epoch: 29 [480/900 (53%)]\tLoss: 0.015233\n",
      "Training epoch: 29 [640/900 (70%)]\tLoss: 0.010179\n",
      "Training epoch: 29 [800/900 (88%)]\tLoss: 0.014346\n",
      "=========> Epoch: 29 Average loss: 0.0122\n",
      "Correlation coefficient: 0.6944\n",
      "Training epoch: 30 [0/900 (0%)]\tLoss: 0.013838\n",
      "Training epoch: 30 [160/900 (18%)]\tLoss: 0.032304\n",
      "Training epoch: 30 [320/900 (35%)]\tLoss: 0.059584\n",
      "Training epoch: 30 [480/900 (53%)]\tLoss: 0.006459\n",
      "Training epoch: 30 [640/900 (70%)]\tLoss: 0.011972\n",
      "Training epoch: 30 [800/900 (88%)]\tLoss: 0.023057\n",
      "=========> Epoch: 30 Average loss: 0.0199\n",
      "Correlation coefficient: 0.6987\n",
      "Training epoch: 31 [0/900 (0%)]\tLoss: 0.014213\n",
      "Training epoch: 31 [160/900 (18%)]\tLoss: 0.119484\n",
      "Training epoch: 31 [320/900 (35%)]\tLoss: 0.016360\n",
      "Training epoch: 31 [480/900 (53%)]\tLoss: 0.024539\n",
      "Training epoch: 31 [640/900 (70%)]\tLoss: 0.020153\n",
      "Training epoch: 31 [800/900 (88%)]\tLoss: 0.037816\n",
      "=========> Epoch: 31 Average loss: 0.0246\n",
      "Correlation coefficient: 0.6946\n",
      "Training epoch: 32 [0/900 (0%)]\tLoss: 0.022356\n",
      "Training epoch: 32 [160/900 (18%)]\tLoss: 0.016759\n",
      "Training epoch: 32 [320/900 (35%)]\tLoss: 0.020918\n",
      "Training epoch: 32 [480/900 (53%)]\tLoss: 0.017842\n",
      "Training epoch: 32 [640/900 (70%)]\tLoss: 0.010748\n",
      "Training epoch: 32 [800/900 (88%)]\tLoss: 0.036610\n",
      "=========> Epoch: 32 Average loss: 0.0264\n",
      "Correlation coefficient: 0.7016\n",
      "Training epoch: 33 [0/900 (0%)]\tLoss: 0.013068\n",
      "Training epoch: 33 [160/900 (18%)]\tLoss: 0.021123\n",
      "Training epoch: 33 [320/900 (35%)]\tLoss: 0.023951\n",
      "Training epoch: 33 [480/900 (53%)]\tLoss: 0.029674\n",
      "Training epoch: 33 [640/900 (70%)]\tLoss: 0.012303\n",
      "Training epoch: 33 [800/900 (88%)]\tLoss: 0.015066\n",
      "=========> Epoch: 33 Average loss: 0.0236\n",
      "Correlation coefficient: 0.6864\n",
      "Training epoch: 34 [0/900 (0%)]\tLoss: 0.004939\n",
      "Training epoch: 34 [160/900 (18%)]\tLoss: 0.018736\n",
      "Training epoch: 34 [320/900 (35%)]\tLoss: 0.008796\n",
      "Training epoch: 34 [480/900 (53%)]\tLoss: 0.033320\n",
      "Training epoch: 34 [640/900 (70%)]\tLoss: 0.012416\n",
      "Training epoch: 34 [800/900 (88%)]\tLoss: 0.009099\n",
      "=========> Epoch: 34 Average loss: 0.0174\n",
      "Correlation coefficient: 0.6986\n",
      "Training epoch: 35 [0/900 (0%)]\tLoss: 0.011542\n",
      "Training epoch: 35 [160/900 (18%)]\tLoss: 0.021018\n",
      "Training epoch: 35 [320/900 (35%)]\tLoss: 0.011085\n",
      "Training epoch: 35 [480/900 (53%)]\tLoss: 0.005814\n",
      "Training epoch: 35 [640/900 (70%)]\tLoss: 0.008271\n",
      "Training epoch: 35 [800/900 (88%)]\tLoss: 0.003745\n",
      "=========> Epoch: 35 Average loss: 0.0103\n",
      "Correlation coefficient: 0.6918\n",
      "Training epoch: 36 [0/900 (0%)]\tLoss: 0.003846\n",
      "Training epoch: 36 [160/900 (18%)]\tLoss: 0.009848\n",
      "Training epoch: 36 [320/900 (35%)]\tLoss: 0.016478\n",
      "Training epoch: 36 [480/900 (53%)]\tLoss: 0.014305\n",
      "Training epoch: 36 [640/900 (70%)]\tLoss: 0.012381\n",
      "Training epoch: 36 [800/900 (88%)]\tLoss: 0.002394\n",
      "=========> Epoch: 36 Average loss: 0.0073\n",
      "Correlation coefficient: 0.7014\n",
      "Training epoch: 37 [0/900 (0%)]\tLoss: 0.004372\n",
      "Training epoch: 37 [160/900 (18%)]\tLoss: 0.005793\n",
      "Training epoch: 37 [320/900 (35%)]\tLoss: 0.005114\n",
      "Training epoch: 37 [480/900 (53%)]\tLoss: 0.004670\n",
      "Training epoch: 37 [640/900 (70%)]\tLoss: 0.002867\n",
      "Training epoch: 37 [800/900 (88%)]\tLoss: 0.007608\n",
      "=========> Epoch: 37 Average loss: 0.0061\n",
      "Correlation coefficient: 0.6954\n",
      "Training epoch: 38 [0/900 (0%)]\tLoss: 0.000554\n",
      "Training epoch: 38 [160/900 (18%)]\tLoss: 0.002072\n",
      "Training epoch: 38 [320/900 (35%)]\tLoss: 0.009258\n",
      "Training epoch: 38 [480/900 (53%)]\tLoss: 0.004464\n",
      "Training epoch: 38 [640/900 (70%)]\tLoss: 0.004160\n",
      "Training epoch: 38 [800/900 (88%)]\tLoss: 0.001865\n",
      "=========> Epoch: 38 Average loss: 0.0052\n",
      "Correlation coefficient: 0.6992\n",
      "Training epoch: 39 [0/900 (0%)]\tLoss: 0.005413\n",
      "Training epoch: 39 [160/900 (18%)]\tLoss: 0.007176\n",
      "Training epoch: 39 [320/900 (35%)]\tLoss: 0.003685\n",
      "Training epoch: 39 [480/900 (53%)]\tLoss: 0.002992\n",
      "Training epoch: 39 [640/900 (70%)]\tLoss: 0.001951\n",
      "Training epoch: 39 [800/900 (88%)]\tLoss: 0.007844\n",
      "=========> Epoch: 39 Average loss: 0.0046\n",
      "Correlation coefficient: 0.7019\n",
      "Training epoch: 40 [0/900 (0%)]\tLoss: 0.006241\n",
      "Training epoch: 40 [160/900 (18%)]\tLoss: 0.001610\n",
      "Training epoch: 40 [320/900 (35%)]\tLoss: 0.001650\n",
      "Training epoch: 40 [480/900 (53%)]\tLoss: 0.003293\n",
      "Training epoch: 40 [640/900 (70%)]\tLoss: 0.003335\n",
      "Training epoch: 40 [800/900 (88%)]\tLoss: 0.001664\n",
      "=========> Epoch: 40 Average loss: 0.0041\n",
      "Correlation coefficient: 0.6979\n",
      "Training epoch: 41 [0/900 (0%)]\tLoss: 0.000767\n",
      "Training epoch: 41 [160/900 (18%)]\tLoss: 0.005195\n",
      "Training epoch: 41 [320/900 (35%)]\tLoss: 0.003381\n",
      "Training epoch: 41 [480/900 (53%)]\tLoss: 0.003391\n",
      "Training epoch: 41 [640/900 (70%)]\tLoss: 0.001956\n",
      "Training epoch: 41 [800/900 (88%)]\tLoss: 0.002839\n",
      "=========> Epoch: 41 Average loss: 0.0030\n",
      "Correlation coefficient: 0.6981\n",
      "Training epoch: 42 [0/900 (0%)]\tLoss: 0.002629\n",
      "Training epoch: 42 [160/900 (18%)]\tLoss: 0.002010\n",
      "Training epoch: 42 [320/900 (35%)]\tLoss: 0.001786\n",
      "Training epoch: 42 [480/900 (53%)]\tLoss: 0.000788\n",
      "Training epoch: 42 [640/900 (70%)]\tLoss: 0.001415\n",
      "Training epoch: 42 [800/900 (88%)]\tLoss: 0.009168\n",
      "=========> Epoch: 42 Average loss: 0.0032\n",
      "Correlation coefficient: 0.6994\n",
      "Training epoch: 43 [0/900 (0%)]\tLoss: 0.003036\n",
      "Training epoch: 43 [160/900 (18%)]\tLoss: 0.001577\n",
      "Training epoch: 43 [320/900 (35%)]\tLoss: 0.002280\n",
      "Training epoch: 43 [480/900 (53%)]\tLoss: 0.002268\n",
      "Training epoch: 43 [640/900 (70%)]\tLoss: 0.001724\n",
      "Training epoch: 43 [800/900 (88%)]\tLoss: 0.002015\n",
      "=========> Epoch: 43 Average loss: 0.0028\n",
      "Correlation coefficient: 0.6998\n",
      "Training epoch: 44 [0/900 (0%)]\tLoss: 0.001398\n",
      "Training epoch: 44 [160/900 (18%)]\tLoss: 0.001169\n",
      "Training epoch: 44 [320/900 (35%)]\tLoss: 0.001449\n",
      "Training epoch: 44 [480/900 (53%)]\tLoss: 0.000659\n",
      "Training epoch: 44 [640/900 (70%)]\tLoss: 0.003193\n",
      "Training epoch: 44 [800/900 (88%)]\tLoss: 0.002467\n",
      "=========> Epoch: 44 Average loss: 0.0025\n",
      "Correlation coefficient: 0.6993\n",
      "Training epoch: 45 [0/900 (0%)]\tLoss: 0.000622\n",
      "Training epoch: 45 [160/900 (18%)]\tLoss: 0.005918\n",
      "Training epoch: 45 [320/900 (35%)]\tLoss: 0.001538\n",
      "Training epoch: 45 [480/900 (53%)]\tLoss: 0.002333\n",
      "Training epoch: 45 [640/900 (70%)]\tLoss: 0.003272\n",
      "Training epoch: 45 [800/900 (88%)]\tLoss: 0.002886\n",
      "=========> Epoch: 45 Average loss: 0.0027\n",
      "Correlation coefficient: 0.7008\n",
      "Training epoch: 46 [0/900 (0%)]\tLoss: 0.001194\n",
      "Training epoch: 46 [160/900 (18%)]\tLoss: 0.005143\n",
      "Training epoch: 46 [320/900 (35%)]\tLoss: 0.006165\n",
      "Training epoch: 46 [480/900 (53%)]\tLoss: 0.004913\n",
      "Training epoch: 46 [640/900 (70%)]\tLoss: 0.003399\n",
      "Training epoch: 46 [800/900 (88%)]\tLoss: 0.001517\n",
      "=========> Epoch: 46 Average loss: 0.0041\n",
      "Correlation coefficient: 0.6941\n",
      "Training epoch: 47 [0/900 (0%)]\tLoss: 0.004112\n",
      "Training epoch: 47 [160/900 (18%)]\tLoss: 0.003832\n",
      "Training epoch: 47 [320/900 (35%)]\tLoss: 0.004363\n",
      "Training epoch: 47 [480/900 (53%)]\tLoss: 0.001407\n",
      "Training epoch: 47 [640/900 (70%)]\tLoss: 0.004657\n",
      "Training epoch: 47 [800/900 (88%)]\tLoss: 0.001582\n",
      "=========> Epoch: 47 Average loss: 0.0045\n",
      "Correlation coefficient: 0.7066\n",
      "Training epoch: 48 [0/900 (0%)]\tLoss: 0.003316\n",
      "Training epoch: 48 [160/900 (18%)]\tLoss: 0.004911\n",
      "Training epoch: 48 [320/900 (35%)]\tLoss: 0.012268\n",
      "Training epoch: 48 [480/900 (53%)]\tLoss: 0.004565\n",
      "Training epoch: 48 [640/900 (70%)]\tLoss: 0.007300\n",
      "Training epoch: 48 [800/900 (88%)]\tLoss: 0.008131\n",
      "=========> Epoch: 48 Average loss: 0.0061\n",
      "Correlation coefficient: 0.6981\n",
      "⏹️  Epoch 48 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 6 best correlation: 0.7068\n",
      "\n",
      "========== Cross-validation Fold 7/10 ==========\n",
      "🔄 Fold 7: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 0.997411\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 1.564118\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 1.069239\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.768449\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.883698\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.799843\n",
      "=========> Epoch: 1 Average loss: 0.9526\n",
      "Correlation coefficient: 0.6151\n",
      "✅ Epoch 1: New best correlation = 0.6151\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.334131\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.523692\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.268894\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.353519\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.328937\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.236835\n",
      "=========> Epoch: 2 Average loss: 0.4873\n",
      "Correlation coefficient: 0.6446\n",
      "✅ Epoch 2: New best correlation = 0.6446\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.241252\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.323898\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.199014\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.113581\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.262284\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.165761\n",
      "=========> Epoch: 3 Average loss: 0.1886\n",
      "Correlation coefficient: 0.6772\n",
      "✅ Epoch 3: New best correlation = 0.6772\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.058703\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.105731\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.067930\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.123793\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.027968\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.048682\n",
      "=========> Epoch: 4 Average loss: 0.0703\n",
      "Correlation coefficient: 0.6659\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.050567\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.044077\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.022457\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.026518\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.015393\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.023136\n",
      "=========> Epoch: 5 Average loss: 0.0289\n",
      "Correlation coefficient: 0.6734\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.013960\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.008752\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.008890\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.006002\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.008857\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.004906\n",
      "=========> Epoch: 6 Average loss: 0.0121\n",
      "Correlation coefficient: 0.6697\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.003826\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.006274\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.005747\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.003730\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.004003\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.004662\n",
      "=========> Epoch: 7 Average loss: 0.0051\n",
      "Correlation coefficient: 0.6734\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.001147\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.002450\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.001576\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.001617\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.001949\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.005121\n",
      "=========> Epoch: 8 Average loss: 0.0028\n",
      "Correlation coefficient: 0.6689\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.008243\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.001587\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.001711\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.001403\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.000482\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.006045\n",
      "=========> Epoch: 9 Average loss: 0.0021\n",
      "Correlation coefficient: 0.6723\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.001265\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.002625\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.000719\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.001479\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.002859\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.001481\n",
      "=========> Epoch: 10 Average loss: 0.0023\n",
      "Correlation coefficient: 0.6691\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.007505\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.002829\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.002887\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.000723\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.003880\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.004649\n",
      "=========> Epoch: 11 Average loss: 0.0028\n",
      "Correlation coefficient: 0.6703\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.004820\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.007871\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.004416\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.004022\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.003066\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.009080\n",
      "=========> Epoch: 12 Average loss: 0.0033\n",
      "Correlation coefficient: 0.6726\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.003875\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.001671\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.004160\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.003613\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.006408\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.005914\n",
      "=========> Epoch: 13 Average loss: 0.0049\n",
      "Correlation coefficient: 0.6705\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.003466\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.003467\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.007135\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.007792\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.004620\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.003059\n",
      "=========> Epoch: 14 Average loss: 0.0067\n",
      "Correlation coefficient: 0.6684\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.004883\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.008644\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.006374\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.005461\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.005967\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.004367\n",
      "=========> Epoch: 15 Average loss: 0.0089\n",
      "Correlation coefficient: 0.6794\n",
      "✅ Epoch 15: New best correlation = 0.6794\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.005387\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.011149\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.006094\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.022967\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.020952\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.009933\n",
      "=========> Epoch: 16 Average loss: 0.0148\n",
      "Correlation coefficient: 0.6649\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.010025\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.015032\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.011215\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.008480\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.012700\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.018020\n",
      "=========> Epoch: 17 Average loss: 0.0182\n",
      "Correlation coefficient: 0.6723\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.014941\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.019669\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.019781\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.027163\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.013799\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.007324\n",
      "=========> Epoch: 18 Average loss: 0.0168\n",
      "Correlation coefficient: 0.6806\n",
      "✅ Epoch 18: New best correlation = 0.6806\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.008469\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.010172\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.015626\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.014283\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.004223\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.022525\n",
      "=========> Epoch: 19 Average loss: 0.0160\n",
      "Correlation coefficient: 0.6693\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.006882\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.015133\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.015172\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.009199\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.017283\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.011559\n",
      "=========> Epoch: 20 Average loss: 0.0104\n",
      "Correlation coefficient: 0.6738\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.011081\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.007915\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.017877\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.010881\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.018700\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.010692\n",
      "=========> Epoch: 21 Average loss: 0.0091\n",
      "Correlation coefficient: 0.6753\n",
      "Training epoch: 22 [0/900 (0%)]\tLoss: 0.007517\n",
      "Training epoch: 22 [160/900 (18%)]\tLoss: 0.010464\n",
      "Training epoch: 22 [320/900 (35%)]\tLoss: 0.003926\n",
      "Training epoch: 22 [480/900 (53%)]\tLoss: 0.005771\n",
      "Training epoch: 22 [640/900 (70%)]\tLoss: 0.012465\n",
      "Training epoch: 22 [800/900 (88%)]\tLoss: 0.007504\n",
      "=========> Epoch: 22 Average loss: 0.0079\n",
      "Correlation coefficient: 0.6726\n",
      "Training epoch: 23 [0/900 (0%)]\tLoss: 0.006468\n",
      "Training epoch: 23 [160/900 (18%)]\tLoss: 0.015679\n",
      "Training epoch: 23 [320/900 (35%)]\tLoss: 0.014605\n",
      "Training epoch: 23 [480/900 (53%)]\tLoss: 0.005486\n",
      "Training epoch: 23 [640/900 (70%)]\tLoss: 0.006867\n",
      "Training epoch: 23 [800/900 (88%)]\tLoss: 0.004400\n",
      "=========> Epoch: 23 Average loss: 0.0077\n",
      "Correlation coefficient: 0.6760\n",
      "Training epoch: 24 [0/900 (0%)]\tLoss: 0.013464\n",
      "Training epoch: 24 [160/900 (18%)]\tLoss: 0.005025\n",
      "Training epoch: 24 [320/900 (35%)]\tLoss: 0.003757\n",
      "Training epoch: 24 [480/900 (53%)]\tLoss: 0.008790\n",
      "Training epoch: 24 [640/900 (70%)]\tLoss: 0.013150\n",
      "Training epoch: 24 [800/900 (88%)]\tLoss: 0.003495\n",
      "=========> Epoch: 24 Average loss: 0.0068\n",
      "Correlation coefficient: 0.6789\n",
      "Training epoch: 25 [0/900 (0%)]\tLoss: 0.004272\n",
      "Training epoch: 25 [160/900 (18%)]\tLoss: 0.003983\n",
      "Training epoch: 25 [320/900 (35%)]\tLoss: 0.003033\n",
      "Training epoch: 25 [480/900 (53%)]\tLoss: 0.030754\n",
      "Training epoch: 25 [640/900 (70%)]\tLoss: 0.004940\n",
      "Training epoch: 25 [800/900 (88%)]\tLoss: 0.010064\n",
      "=========> Epoch: 25 Average loss: 0.0065\n",
      "Correlation coefficient: 0.6671\n",
      "Training epoch: 26 [0/900 (0%)]\tLoss: 0.004046\n",
      "Training epoch: 26 [160/900 (18%)]\tLoss: 0.004378\n",
      "Training epoch: 26 [320/900 (35%)]\tLoss: 0.005679\n",
      "Training epoch: 26 [480/900 (53%)]\tLoss: 0.010277\n",
      "Training epoch: 26 [640/900 (70%)]\tLoss: 0.014433\n",
      "Training epoch: 26 [800/900 (88%)]\tLoss: 0.009937\n",
      "=========> Epoch: 26 Average loss: 0.0064\n",
      "Correlation coefficient: 0.6718\n",
      "Training epoch: 27 [0/900 (0%)]\tLoss: 0.003121\n",
      "Training epoch: 27 [160/900 (18%)]\tLoss: 0.003744\n",
      "Training epoch: 27 [320/900 (35%)]\tLoss: 0.008730\n",
      "Training epoch: 27 [480/900 (53%)]\tLoss: 0.005788\n",
      "Training epoch: 27 [640/900 (70%)]\tLoss: 0.005749\n",
      "Training epoch: 27 [800/900 (88%)]\tLoss: 0.005085\n",
      "=========> Epoch: 27 Average loss: 0.0067\n",
      "Correlation coefficient: 0.6742\n",
      "Training epoch: 28 [0/900 (0%)]\tLoss: 0.004311\n",
      "Training epoch: 28 [160/900 (18%)]\tLoss: 0.009402\n",
      "Training epoch: 28 [320/900 (35%)]\tLoss: 0.019788\n",
      "Training epoch: 28 [480/900 (53%)]\tLoss: 0.007456\n",
      "Training epoch: 28 [640/900 (70%)]\tLoss: 0.005906\n",
      "Training epoch: 28 [800/900 (88%)]\tLoss: 0.006417\n",
      "=========> Epoch: 28 Average loss: 0.0060\n",
      "Correlation coefficient: 0.6747\n",
      "Training epoch: 29 [0/900 (0%)]\tLoss: 0.006740\n",
      "Training epoch: 29 [160/900 (18%)]\tLoss: 0.012094\n",
      "Training epoch: 29 [320/900 (35%)]\tLoss: 0.012108\n",
      "Training epoch: 29 [480/900 (53%)]\tLoss: 0.010321\n",
      "Training epoch: 29 [640/900 (70%)]\tLoss: 0.004148\n",
      "Training epoch: 29 [800/900 (88%)]\tLoss: 0.009410\n",
      "=========> Epoch: 29 Average loss: 0.0077\n",
      "Correlation coefficient: 0.6747\n",
      "Training epoch: 30 [0/900 (0%)]\tLoss: 0.007369\n",
      "Training epoch: 30 [160/900 (18%)]\tLoss: 0.008789\n",
      "Training epoch: 30 [320/900 (35%)]\tLoss: 0.010843\n",
      "Training epoch: 30 [480/900 (53%)]\tLoss: 0.006144\n",
      "Training epoch: 30 [640/900 (70%)]\tLoss: 0.008708\n",
      "Training epoch: 30 [800/900 (88%)]\tLoss: 0.010053\n",
      "=========> Epoch: 30 Average loss: 0.0091\n",
      "Correlation coefficient: 0.6672\n",
      "Training epoch: 31 [0/900 (0%)]\tLoss: 0.003134\n",
      "Training epoch: 31 [160/900 (18%)]\tLoss: 0.005178\n",
      "Training epoch: 31 [320/900 (35%)]\tLoss: 0.007458\n",
      "Training epoch: 31 [480/900 (53%)]\tLoss: 0.006135\n",
      "Training epoch: 31 [640/900 (70%)]\tLoss: 0.017641\n",
      "Training epoch: 31 [800/900 (88%)]\tLoss: 0.004931\n",
      "=========> Epoch: 31 Average loss: 0.0083\n",
      "Correlation coefficient: 0.6737\n",
      "Training epoch: 32 [0/900 (0%)]\tLoss: 0.002267\n",
      "Training epoch: 32 [160/900 (18%)]\tLoss: 0.003834\n",
      "Training epoch: 32 [320/900 (35%)]\tLoss: 0.008944\n",
      "Training epoch: 32 [480/900 (53%)]\tLoss: 0.004461\n",
      "Training epoch: 32 [640/900 (70%)]\tLoss: 0.007801\n",
      "Training epoch: 32 [800/900 (88%)]\tLoss: 0.008449\n",
      "=========> Epoch: 32 Average loss: 0.0085\n",
      "Correlation coefficient: 0.6720\n",
      "Training epoch: 33 [0/900 (0%)]\tLoss: 0.009108\n",
      "Training epoch: 33 [160/900 (18%)]\tLoss: 0.016057\n",
      "Training epoch: 33 [320/900 (35%)]\tLoss: 0.003502\n",
      "Training epoch: 33 [480/900 (53%)]\tLoss: 0.006145\n",
      "Training epoch: 33 [640/900 (70%)]\tLoss: 0.008636\n",
      "Training epoch: 33 [800/900 (88%)]\tLoss: 0.009466\n",
      "=========> Epoch: 33 Average loss: 0.0091\n",
      "Correlation coefficient: 0.6702\n",
      "Training epoch: 34 [0/900 (0%)]\tLoss: 0.003213\n",
      "Training epoch: 34 [160/900 (18%)]\tLoss: 0.010747\n",
      "Training epoch: 34 [320/900 (35%)]\tLoss: 0.005293\n",
      "Training epoch: 34 [480/900 (53%)]\tLoss: 0.007234\n",
      "Training epoch: 34 [640/900 (70%)]\tLoss: 0.013575\n",
      "Training epoch: 34 [800/900 (88%)]\tLoss: 0.012878\n",
      "=========> Epoch: 34 Average loss: 0.0105\n",
      "Correlation coefficient: 0.6747\n",
      "Training epoch: 35 [0/900 (0%)]\tLoss: 0.020339\n",
      "Training epoch: 35 [160/900 (18%)]\tLoss: 0.017959\n",
      "Training epoch: 35 [320/900 (35%)]\tLoss: 0.012569\n",
      "Training epoch: 35 [480/900 (53%)]\tLoss: 0.013449\n",
      "Training epoch: 35 [640/900 (70%)]\tLoss: 0.006812\n",
      "Training epoch: 35 [800/900 (88%)]\tLoss: 0.010627\n",
      "=========> Epoch: 35 Average loss: 0.0149\n",
      "Correlation coefficient: 0.6609\n",
      "Training epoch: 36 [0/900 (0%)]\tLoss: 0.012977\n",
      "Training epoch: 36 [160/900 (18%)]\tLoss: 0.014938\n",
      "Training epoch: 36 [320/900 (35%)]\tLoss: 0.006720\n",
      "Training epoch: 36 [480/900 (53%)]\tLoss: 0.010180\n",
      "Training epoch: 36 [640/900 (70%)]\tLoss: 0.008434\n",
      "Training epoch: 36 [800/900 (88%)]\tLoss: 0.015895\n",
      "=========> Epoch: 36 Average loss: 0.0162\n",
      "Correlation coefficient: 0.6672\n",
      "Training epoch: 37 [0/900 (0%)]\tLoss: 0.003611\n",
      "Training epoch: 37 [160/900 (18%)]\tLoss: 0.017009\n",
      "Training epoch: 37 [320/900 (35%)]\tLoss: 0.009716\n",
      "Training epoch: 37 [480/900 (53%)]\tLoss: 0.027472\n",
      "Training epoch: 37 [640/900 (70%)]\tLoss: 0.004693\n",
      "Training epoch: 37 [800/900 (88%)]\tLoss: 0.008847\n",
      "=========> Epoch: 37 Average loss: 0.0150\n",
      "Correlation coefficient: 0.6714\n",
      "Training epoch: 38 [0/900 (0%)]\tLoss: 0.007955\n",
      "Training epoch: 38 [160/900 (18%)]\tLoss: 0.014428\n",
      "Training epoch: 38 [320/900 (35%)]\tLoss: 0.027978\n",
      "Training epoch: 38 [480/900 (53%)]\tLoss: 0.006783\n",
      "Training epoch: 38 [640/900 (70%)]\tLoss: 0.013835\n",
      "Training epoch: 38 [800/900 (88%)]\tLoss: 0.007208\n",
      "=========> Epoch: 38 Average loss: 0.0152\n",
      "Correlation coefficient: 0.6765\n",
      "⏹️  Epoch 38 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 7 best correlation: 0.6806\n",
      "\n",
      "========== Cross-validation Fold 8/10 ==========\n",
      "🔄 Fold 8: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 1.095780\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 0.930483\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 0.693882\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.871993\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.323868\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.557445\n",
      "=========> Epoch: 1 Average loss: 0.8732\n",
      "Correlation coefficient: 0.6457\n",
      "✅ Epoch 1: New best correlation = 0.6457\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.488476\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.255179\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.329861\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.275143\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.291035\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.304935\n",
      "=========> Epoch: 2 Average loss: 0.3622\n",
      "Correlation coefficient: 0.6577\n",
      "✅ Epoch 2: New best correlation = 0.6577\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.193409\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.137280\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.059582\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.073927\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.098939\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.130073\n",
      "=========> Epoch: 3 Average loss: 0.1041\n",
      "Correlation coefficient: 0.6419\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.070257\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.079847\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.034256\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.023939\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.024476\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.038979\n",
      "=========> Epoch: 4 Average loss: 0.0370\n",
      "Correlation coefficient: 0.6626\n",
      "✅ Epoch 4: New best correlation = 0.6626\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.012191\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.037271\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.017757\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.009173\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.037050\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.016187\n",
      "=========> Epoch: 5 Average loss: 0.0192\n",
      "Correlation coefficient: 0.6622\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.009053\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.016561\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.012370\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.071682\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.011761\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.011375\n",
      "=========> Epoch: 6 Average loss: 0.0150\n",
      "Correlation coefficient: 0.6669\n",
      "✅ Epoch 6: New best correlation = 0.6669\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.015135\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.004452\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.006652\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.011384\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.006023\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.004638\n",
      "=========> Epoch: 7 Average loss: 0.0133\n",
      "Correlation coefficient: 0.6629\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.005996\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.004019\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.008171\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.006606\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.010481\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.004760\n",
      "=========> Epoch: 8 Average loss: 0.0087\n",
      "Correlation coefficient: 0.6689\n",
      "✅ Epoch 8: New best correlation = 0.6689\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.002174\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.005754\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.008609\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.006464\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.006504\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.003228\n",
      "=========> Epoch: 9 Average loss: 0.0082\n",
      "Correlation coefficient: 0.6653\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.004456\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.004708\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.005793\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.006983\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.004533\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.005479\n",
      "=========> Epoch: 10 Average loss: 0.0074\n",
      "Correlation coefficient: 0.6592\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.003592\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.008789\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.003213\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.007658\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.004881\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.006152\n",
      "=========> Epoch: 11 Average loss: 0.0067\n",
      "Correlation coefficient: 0.6683\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.003264\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.005540\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.005610\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.007117\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.005731\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.009555\n",
      "=========> Epoch: 12 Average loss: 0.0070\n",
      "Correlation coefficient: 0.6641\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.004994\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.005970\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.007030\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.006478\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.010897\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.005602\n",
      "=========> Epoch: 13 Average loss: 0.0073\n",
      "Correlation coefficient: 0.6670\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.006764\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.011311\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.008220\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.007572\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.008925\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.006694\n",
      "=========> Epoch: 14 Average loss: 0.0092\n",
      "Correlation coefficient: 0.6669\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.004554\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.009113\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.005696\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.011236\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.005720\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.011695\n",
      "=========> Epoch: 15 Average loss: 0.0123\n",
      "Correlation coefficient: 0.6690\n",
      "✅ Epoch 15: New best correlation = 0.6690\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.018977\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.011522\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.015015\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.008184\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.019785\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.013962\n",
      "=========> Epoch: 16 Average loss: 0.0147\n",
      "Correlation coefficient: 0.6659\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.018202\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.006773\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.013196\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.015005\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.012090\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.022654\n",
      "=========> Epoch: 17 Average loss: 0.0145\n",
      "Correlation coefficient: 0.6625\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.013161\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.017532\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.017816\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.024798\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.016389\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.021049\n",
      "=========> Epoch: 18 Average loss: 0.0153\n",
      "Correlation coefficient: 0.6654\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.012761\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.012460\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.033976\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.063897\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.016937\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.016232\n",
      "=========> Epoch: 19 Average loss: 0.0176\n",
      "Correlation coefficient: 0.6647\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.006171\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.018599\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.005911\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.010330\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.011658\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.006786\n",
      "=========> Epoch: 20 Average loss: 0.0160\n",
      "Correlation coefficient: 0.6646\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.017680\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.005016\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.009811\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.004005\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.006405\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.014531\n",
      "=========> Epoch: 21 Average loss: 0.0122\n",
      "Correlation coefficient: 0.6638\n",
      "Training epoch: 22 [0/900 (0%)]\tLoss: 0.009786\n",
      "Training epoch: 22 [160/900 (18%)]\tLoss: 0.025512\n",
      "Training epoch: 22 [320/900 (35%)]\tLoss: 0.010356\n",
      "Training epoch: 22 [480/900 (53%)]\tLoss: 0.007493\n",
      "Training epoch: 22 [640/900 (70%)]\tLoss: 0.013818\n",
      "Training epoch: 22 [800/900 (88%)]\tLoss: 0.010693\n",
      "=========> Epoch: 22 Average loss: 0.0115\n",
      "Correlation coefficient: 0.6685\n",
      "Training epoch: 23 [0/900 (0%)]\tLoss: 0.014577\n",
      "Training epoch: 23 [160/900 (18%)]\tLoss: 0.005417\n",
      "Training epoch: 23 [320/900 (35%)]\tLoss: 0.011500\n",
      "Training epoch: 23 [480/900 (53%)]\tLoss: 0.010378\n",
      "Training epoch: 23 [640/900 (70%)]\tLoss: 0.012198\n",
      "Training epoch: 23 [800/900 (88%)]\tLoss: 0.003926\n",
      "=========> Epoch: 23 Average loss: 0.0103\n",
      "Correlation coefficient: 0.6670\n",
      "Training epoch: 24 [0/900 (0%)]\tLoss: 0.010408\n",
      "Training epoch: 24 [160/900 (18%)]\tLoss: 0.011693\n",
      "Training epoch: 24 [320/900 (35%)]\tLoss: 0.008731\n",
      "Training epoch: 24 [480/900 (53%)]\tLoss: 0.006088\n",
      "Training epoch: 24 [640/900 (70%)]\tLoss: 0.007455\n",
      "Training epoch: 24 [800/900 (88%)]\tLoss: 0.007223\n",
      "=========> Epoch: 24 Average loss: 0.0092\n",
      "Correlation coefficient: 0.6714\n",
      "✅ Epoch 24: New best correlation = 0.6714\n",
      "Training epoch: 25 [0/900 (0%)]\tLoss: 0.006582\n",
      "Training epoch: 25 [160/900 (18%)]\tLoss: 0.012336\n",
      "Training epoch: 25 [320/900 (35%)]\tLoss: 0.007860\n",
      "Training epoch: 25 [480/900 (53%)]\tLoss: 0.007047\n",
      "Training epoch: 25 [640/900 (70%)]\tLoss: 0.002529\n",
      "Training epoch: 25 [800/900 (88%)]\tLoss: 0.007034\n",
      "=========> Epoch: 25 Average loss: 0.0087\n",
      "Correlation coefficient: 0.6682\n",
      "Training epoch: 26 [0/900 (0%)]\tLoss: 0.003843\n",
      "Training epoch: 26 [160/900 (18%)]\tLoss: 0.010472\n",
      "Training epoch: 26 [320/900 (35%)]\tLoss: 0.006667\n",
      "Training epoch: 26 [480/900 (53%)]\tLoss: 0.024806\n",
      "Training epoch: 26 [640/900 (70%)]\tLoss: 0.007735\n",
      "Training epoch: 26 [800/900 (88%)]\tLoss: 0.006502\n",
      "=========> Epoch: 26 Average loss: 0.0074\n",
      "Correlation coefficient: 0.6740\n",
      "✅ Epoch 26: New best correlation = 0.6740\n",
      "Training epoch: 27 [0/900 (0%)]\tLoss: 0.004818\n",
      "Training epoch: 27 [160/900 (18%)]\tLoss: 0.004932\n",
      "Training epoch: 27 [320/900 (35%)]\tLoss: 0.002401\n",
      "Training epoch: 27 [480/900 (53%)]\tLoss: 0.005519\n",
      "Training epoch: 27 [640/900 (70%)]\tLoss: 0.009574\n",
      "Training epoch: 27 [800/900 (88%)]\tLoss: 0.004637\n",
      "=========> Epoch: 27 Average loss: 0.0058\n",
      "Correlation coefficient: 0.6749\n",
      "✅ Epoch 27: New best correlation = 0.6749\n",
      "Training epoch: 28 [0/900 (0%)]\tLoss: 0.004810\n",
      "Training epoch: 28 [160/900 (18%)]\tLoss: 0.004615\n",
      "Training epoch: 28 [320/900 (35%)]\tLoss: 0.003681\n",
      "Training epoch: 28 [480/900 (53%)]\tLoss: 0.006192\n",
      "Training epoch: 28 [640/900 (70%)]\tLoss: 0.007251\n",
      "Training epoch: 28 [800/900 (88%)]\tLoss: 0.002036\n",
      "=========> Epoch: 28 Average loss: 0.0055\n",
      "Correlation coefficient: 0.6630\n",
      "Training epoch: 29 [0/900 (0%)]\tLoss: 0.009844\n",
      "Training epoch: 29 [160/900 (18%)]\tLoss: 0.003859\n",
      "Training epoch: 29 [320/900 (35%)]\tLoss: 0.003342\n",
      "Training epoch: 29 [480/900 (53%)]\tLoss: 0.002995\n",
      "Training epoch: 29 [640/900 (70%)]\tLoss: 0.004271\n",
      "Training epoch: 29 [800/900 (88%)]\tLoss: 0.002826\n",
      "=========> Epoch: 29 Average loss: 0.0046\n",
      "Correlation coefficient: 0.6773\n",
      "✅ Epoch 29: New best correlation = 0.6773\n",
      "Training epoch: 30 [0/900 (0%)]\tLoss: 0.004017\n",
      "Training epoch: 30 [160/900 (18%)]\tLoss: 0.004356\n",
      "Training epoch: 30 [320/900 (35%)]\tLoss: 0.006934\n",
      "Training epoch: 30 [480/900 (53%)]\tLoss: 0.003402\n",
      "Training epoch: 30 [640/900 (70%)]\tLoss: 0.010185\n",
      "Training epoch: 30 [800/900 (88%)]\tLoss: 0.005867\n",
      "=========> Epoch: 30 Average loss: 0.0047\n",
      "Correlation coefficient: 0.6700\n",
      "Training epoch: 31 [0/900 (0%)]\tLoss: 0.001971\n",
      "Training epoch: 31 [160/900 (18%)]\tLoss: 0.005259\n",
      "Training epoch: 31 [320/900 (35%)]\tLoss: 0.006967\n",
      "Training epoch: 31 [480/900 (53%)]\tLoss: 0.003244\n",
      "Training epoch: 31 [640/900 (70%)]\tLoss: 0.003200\n",
      "Training epoch: 31 [800/900 (88%)]\tLoss: 0.004522\n",
      "=========> Epoch: 31 Average loss: 0.0047\n",
      "Correlation coefficient: 0.6679\n",
      "Training epoch: 32 [0/900 (0%)]\tLoss: 0.002800\n",
      "Training epoch: 32 [160/900 (18%)]\tLoss: 0.001189\n",
      "Training epoch: 32 [320/900 (35%)]\tLoss: 0.004076\n",
      "Training epoch: 32 [480/900 (53%)]\tLoss: 0.001569\n",
      "Training epoch: 32 [640/900 (70%)]\tLoss: 0.005691\n",
      "Training epoch: 32 [800/900 (88%)]\tLoss: 0.004070\n",
      "=========> Epoch: 32 Average loss: 0.0042\n",
      "Correlation coefficient: 0.6742\n",
      "Training epoch: 33 [0/900 (0%)]\tLoss: 0.002398\n",
      "Training epoch: 33 [160/900 (18%)]\tLoss: 0.002766\n",
      "Training epoch: 33 [320/900 (35%)]\tLoss: 0.005922\n",
      "Training epoch: 33 [480/900 (53%)]\tLoss: 0.010308\n",
      "Training epoch: 33 [640/900 (70%)]\tLoss: 0.003807\n",
      "Training epoch: 33 [800/900 (88%)]\tLoss: 0.004481\n",
      "=========> Epoch: 33 Average loss: 0.0047\n",
      "Correlation coefficient: 0.6734\n",
      "Training epoch: 34 [0/900 (0%)]\tLoss: 0.002806\n",
      "Training epoch: 34 [160/900 (18%)]\tLoss: 0.006386\n",
      "Training epoch: 34 [320/900 (35%)]\tLoss: 0.006063\n",
      "Training epoch: 34 [480/900 (53%)]\tLoss: 0.002250\n",
      "Training epoch: 34 [640/900 (70%)]\tLoss: 0.004087\n",
      "Training epoch: 34 [800/900 (88%)]\tLoss: 0.005723\n",
      "=========> Epoch: 34 Average loss: 0.0069\n",
      "Correlation coefficient: 0.6712\n",
      "Training epoch: 35 [0/900 (0%)]\tLoss: 0.006570\n",
      "Training epoch: 35 [160/900 (18%)]\tLoss: 0.005197\n",
      "Training epoch: 35 [320/900 (35%)]\tLoss: 0.010847\n",
      "Training epoch: 35 [480/900 (53%)]\tLoss: 0.007778\n",
      "Training epoch: 35 [640/900 (70%)]\tLoss: 0.001802\n",
      "Training epoch: 35 [800/900 (88%)]\tLoss: 0.078020\n",
      "=========> Epoch: 35 Average loss: 0.0125\n",
      "Correlation coefficient: 0.6764\n",
      "Training epoch: 36 [0/900 (0%)]\tLoss: 0.035409\n",
      "Training epoch: 36 [160/900 (18%)]\tLoss: 0.017551\n",
      "Training epoch: 36 [320/900 (35%)]\tLoss: 0.048828\n",
      "Training epoch: 36 [480/900 (53%)]\tLoss: 0.041239\n",
      "Training epoch: 36 [640/900 (70%)]\tLoss: 0.032450\n",
      "Training epoch: 36 [800/900 (88%)]\tLoss: 0.009290\n",
      "=========> Epoch: 36 Average loss: 0.0377\n",
      "Correlation coefficient: 0.6671\n",
      "Training epoch: 37 [0/900 (0%)]\tLoss: 0.059312\n",
      "Training epoch: 37 [160/900 (18%)]\tLoss: 0.034491\n",
      "Training epoch: 37 [320/900 (35%)]\tLoss: 0.041834\n",
      "Training epoch: 37 [480/900 (53%)]\tLoss: 0.067385\n",
      "Training epoch: 37 [640/900 (70%)]\tLoss: 0.118280\n",
      "Training epoch: 37 [800/900 (88%)]\tLoss: 0.037658\n",
      "=========> Epoch: 37 Average loss: 0.0563\n",
      "Correlation coefficient: 0.6590\n",
      "Training epoch: 38 [0/900 (0%)]\tLoss: 0.164217\n",
      "Training epoch: 38 [160/900 (18%)]\tLoss: 0.063403\n",
      "Training epoch: 38 [320/900 (35%)]\tLoss: 0.032736\n",
      "Training epoch: 38 [480/900 (53%)]\tLoss: 0.031097\n",
      "Training epoch: 38 [640/900 (70%)]\tLoss: 0.101889\n",
      "Training epoch: 38 [800/900 (88%)]\tLoss: 0.024456\n",
      "=========> Epoch: 38 Average loss: 0.0463\n",
      "Correlation coefficient: 0.6420\n",
      "Training epoch: 39 [0/900 (0%)]\tLoss: 0.040267\n",
      "Training epoch: 39 [160/900 (18%)]\tLoss: 0.015083\n",
      "Training epoch: 39 [320/900 (35%)]\tLoss: 0.019085\n",
      "Training epoch: 39 [480/900 (53%)]\tLoss: 0.035473\n",
      "Training epoch: 39 [640/900 (70%)]\tLoss: 0.068291\n",
      "Training epoch: 39 [800/900 (88%)]\tLoss: 0.057407\n",
      "=========> Epoch: 39 Average loss: 0.0409\n",
      "Correlation coefficient: 0.6510\n",
      "Training epoch: 40 [0/900 (0%)]\tLoss: 0.031148\n",
      "Training epoch: 40 [160/900 (18%)]\tLoss: 0.009470\n",
      "Training epoch: 40 [320/900 (35%)]\tLoss: 0.043575\n",
      "Training epoch: 40 [480/900 (53%)]\tLoss: 0.015728\n",
      "Training epoch: 40 [640/900 (70%)]\tLoss: 0.027042\n",
      "Training epoch: 40 [800/900 (88%)]\tLoss: 0.013399\n",
      "=========> Epoch: 40 Average loss: 0.0267\n",
      "Correlation coefficient: 0.6700\n",
      "Training epoch: 41 [0/900 (0%)]\tLoss: 0.022210\n",
      "Training epoch: 41 [160/900 (18%)]\tLoss: 0.024304\n",
      "Training epoch: 41 [320/900 (35%)]\tLoss: 0.018342\n",
      "Training epoch: 41 [480/900 (53%)]\tLoss: 0.026684\n",
      "Training epoch: 41 [640/900 (70%)]\tLoss: 0.008648\n",
      "Training epoch: 41 [800/900 (88%)]\tLoss: 0.011191\n",
      "=========> Epoch: 41 Average loss: 0.0151\n",
      "Correlation coefficient: 0.6655\n",
      "Training epoch: 42 [0/900 (0%)]\tLoss: 0.009922\n",
      "Training epoch: 42 [160/900 (18%)]\tLoss: 0.007074\n",
      "Training epoch: 42 [320/900 (35%)]\tLoss: 0.005384\n",
      "Training epoch: 42 [480/900 (53%)]\tLoss: 0.014766\n",
      "Training epoch: 42 [640/900 (70%)]\tLoss: 0.004285\n",
      "Training epoch: 42 [800/900 (88%)]\tLoss: 0.004072\n",
      "=========> Epoch: 42 Average loss: 0.0081\n",
      "Correlation coefficient: 0.6691\n",
      "Training epoch: 43 [0/900 (0%)]\tLoss: 0.010008\n",
      "Training epoch: 43 [160/900 (18%)]\tLoss: 0.003415\n",
      "Training epoch: 43 [320/900 (35%)]\tLoss: 0.001584\n",
      "Training epoch: 43 [480/900 (53%)]\tLoss: 0.003326\n",
      "Training epoch: 43 [640/900 (70%)]\tLoss: 0.004298\n",
      "Training epoch: 43 [800/900 (88%)]\tLoss: 0.004215\n",
      "=========> Epoch: 43 Average loss: 0.0050\n",
      "Correlation coefficient: 0.6659\n",
      "Training epoch: 44 [0/900 (0%)]\tLoss: 0.002601\n",
      "Training epoch: 44 [160/900 (18%)]\tLoss: 0.003256\n",
      "Training epoch: 44 [320/900 (35%)]\tLoss: 0.001947\n",
      "Training epoch: 44 [480/900 (53%)]\tLoss: 0.001235\n",
      "Training epoch: 44 [640/900 (70%)]\tLoss: 0.005447\n",
      "Training epoch: 44 [800/900 (88%)]\tLoss: 0.001498\n",
      "=========> Epoch: 44 Average loss: 0.0025\n",
      "Correlation coefficient: 0.6749\n",
      "Training epoch: 45 [0/900 (0%)]\tLoss: 0.002201\n",
      "Training epoch: 45 [160/900 (18%)]\tLoss: 0.001781\n",
      "Training epoch: 45 [320/900 (35%)]\tLoss: 0.000900\n",
      "Training epoch: 45 [480/900 (53%)]\tLoss: 0.001299\n",
      "Training epoch: 45 [640/900 (70%)]\tLoss: 0.001303\n",
      "Training epoch: 45 [800/900 (88%)]\tLoss: 0.001868\n",
      "=========> Epoch: 45 Average loss: 0.0019\n",
      "Correlation coefficient: 0.6693\n",
      "Training epoch: 46 [0/900 (0%)]\tLoss: 0.001255\n",
      "Training epoch: 46 [160/900 (18%)]\tLoss: 0.001243\n",
      "Training epoch: 46 [320/900 (35%)]\tLoss: 0.001331\n",
      "Training epoch: 46 [480/900 (53%)]\tLoss: 0.000335\n",
      "Training epoch: 46 [640/900 (70%)]\tLoss: 0.001896\n",
      "Training epoch: 46 [800/900 (88%)]\tLoss: 0.000765\n",
      "=========> Epoch: 46 Average loss: 0.0015\n",
      "Correlation coefficient: 0.6700\n",
      "Training epoch: 47 [0/900 (0%)]\tLoss: 0.002064\n",
      "Training epoch: 47 [160/900 (18%)]\tLoss: 0.000622\n",
      "Training epoch: 47 [320/900 (35%)]\tLoss: 0.000811\n",
      "Training epoch: 47 [480/900 (53%)]\tLoss: 0.003273\n",
      "Training epoch: 47 [640/900 (70%)]\tLoss: 0.001260\n",
      "Training epoch: 47 [800/900 (88%)]\tLoss: 0.000687\n",
      "=========> Epoch: 47 Average loss: 0.0017\n",
      "Correlation coefficient: 0.6695\n",
      "Training epoch: 48 [0/900 (0%)]\tLoss: 0.000402\n",
      "Training epoch: 48 [160/900 (18%)]\tLoss: 0.000588\n",
      "Training epoch: 48 [320/900 (35%)]\tLoss: 0.000500\n",
      "Training epoch: 48 [480/900 (53%)]\tLoss: 0.002458\n",
      "Training epoch: 48 [640/900 (70%)]\tLoss: 0.001734\n",
      "Training epoch: 48 [800/900 (88%)]\tLoss: 0.001143\n",
      "=========> Epoch: 48 Average loss: 0.0011\n",
      "Correlation coefficient: 0.6695\n",
      "Training epoch: 49 [0/900 (0%)]\tLoss: 0.000555\n",
      "Training epoch: 49 [160/900 (18%)]\tLoss: 0.000234\n",
      "Training epoch: 49 [320/900 (35%)]\tLoss: 0.000348\n",
      "Training epoch: 49 [480/900 (53%)]\tLoss: 0.001043\n",
      "Training epoch: 49 [640/900 (70%)]\tLoss: 0.000455\n",
      "Training epoch: 49 [800/900 (88%)]\tLoss: 0.000371\n",
      "=========> Epoch: 49 Average loss: 0.0006\n",
      "Correlation coefficient: 0.6701\n",
      "⏹️  Epoch 49 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 8 best correlation: 0.6773\n",
      "\n",
      "========== Cross-validation Fold 9/10 ==========\n",
      "🔄 Fold 9: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 1.007073\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 0.691066\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 0.523900\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 0.934534\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.930755\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.169314\n",
      "=========> Epoch: 1 Average loss: 0.7169\n",
      "Correlation coefficient: 0.6849\n",
      "✅ Epoch 1: New best correlation = 0.6849\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.494304\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.417067\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.475319\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.238368\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.234152\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.256707\n",
      "=========> Epoch: 2 Average loss: 0.2973\n",
      "Correlation coefficient: 0.7108\n",
      "✅ Epoch 2: New best correlation = 0.7108\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.167080\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.091052\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.085299\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.185434\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.082072\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.073885\n",
      "=========> Epoch: 3 Average loss: 0.1251\n",
      "Correlation coefficient: 0.6852\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.075818\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.046177\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.038838\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.049831\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.017057\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.031047\n",
      "=========> Epoch: 4 Average loss: 0.0474\n",
      "Correlation coefficient: 0.7150\n",
      "✅ Epoch 4: New best correlation = 0.7150\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.017721\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.008277\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.024328\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.010570\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.020569\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.011424\n",
      "=========> Epoch: 5 Average loss: 0.0214\n",
      "Correlation coefficient: 0.6994\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.019455\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.007918\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.008321\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.009517\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.002907\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.005273\n",
      "=========> Epoch: 6 Average loss: 0.0119\n",
      "Correlation coefficient: 0.7176\n",
      "✅ Epoch 6: New best correlation = 0.7176\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.012014\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.006394\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.010581\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.011802\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.007499\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.019587\n",
      "=========> Epoch: 7 Average loss: 0.0150\n",
      "Correlation coefficient: 0.7123\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.027719\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.011113\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.026826\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.013702\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.038434\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.013524\n",
      "=========> Epoch: 8 Average loss: 0.0153\n",
      "Correlation coefficient: 0.7030\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.020239\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.007635\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.009159\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.011763\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.006908\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.012256\n",
      "=========> Epoch: 9 Average loss: 0.0162\n",
      "Correlation coefficient: 0.6977\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.013823\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.010778\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.006888\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.012755\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.014550\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.019609\n",
      "=========> Epoch: 10 Average loss: 0.0164\n",
      "Correlation coefficient: 0.7103\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.011127\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.008070\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.010851\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.005582\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.008314\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.020029\n",
      "=========> Epoch: 11 Average loss: 0.0122\n",
      "Correlation coefficient: 0.7002\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.009151\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.034485\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.006174\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.020490\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.005007\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.010763\n",
      "=========> Epoch: 12 Average loss: 0.0112\n",
      "Correlation coefficient: 0.7062\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.004319\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.013895\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.009083\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.015973\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.023217\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.010281\n",
      "=========> Epoch: 13 Average loss: 0.0127\n",
      "Correlation coefficient: 0.7045\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.011075\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.017313\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.016756\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.010583\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.008634\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.006603\n",
      "=========> Epoch: 14 Average loss: 0.0134\n",
      "Correlation coefficient: 0.7007\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.006931\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.009285\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.009366\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.015420\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.042701\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.006844\n",
      "=========> Epoch: 15 Average loss: 0.0115\n",
      "Correlation coefficient: 0.7086\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.008906\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.007549\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.016432\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.007351\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.006316\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.005807\n",
      "=========> Epoch: 16 Average loss: 0.0104\n",
      "Correlation coefficient: 0.7029\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.005222\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.005521\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.012298\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.008797\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.008905\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.005974\n",
      "=========> Epoch: 17 Average loss: 0.0086\n",
      "Correlation coefficient: 0.7069\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.007187\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.012528\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.010281\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.002327\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.005009\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.005478\n",
      "=========> Epoch: 18 Average loss: 0.0112\n",
      "Correlation coefficient: 0.7055\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.007944\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.016047\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.006776\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.022607\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.009204\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.007925\n",
      "=========> Epoch: 19 Average loss: 0.0137\n",
      "Correlation coefficient: 0.7025\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.005563\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.006677\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.033842\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.012178\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.004042\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.012825\n",
      "=========> Epoch: 20 Average loss: 0.0120\n",
      "Correlation coefficient: 0.7091\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.005536\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.006323\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.016682\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.024007\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.014210\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.018112\n",
      "=========> Epoch: 21 Average loss: 0.0150\n",
      "Correlation coefficient: 0.7053\n",
      "Training epoch: 22 [0/900 (0%)]\tLoss: 0.029893\n",
      "Training epoch: 22 [160/900 (18%)]\tLoss: 0.042707\n",
      "Training epoch: 22 [320/900 (35%)]\tLoss: 0.015347\n",
      "Training epoch: 22 [480/900 (53%)]\tLoss: 0.021326\n",
      "Training epoch: 22 [640/900 (70%)]\tLoss: 0.012095\n",
      "Training epoch: 22 [800/900 (88%)]\tLoss: 0.010266\n",
      "=========> Epoch: 22 Average loss: 0.0174\n",
      "Correlation coefficient: 0.7012\n",
      "Training epoch: 23 [0/900 (0%)]\tLoss: 0.006235\n",
      "Training epoch: 23 [160/900 (18%)]\tLoss: 0.015555\n",
      "Training epoch: 23 [320/900 (35%)]\tLoss: 0.016291\n",
      "Training epoch: 23 [480/900 (53%)]\tLoss: 0.022407\n",
      "Training epoch: 23 [640/900 (70%)]\tLoss: 0.010038\n",
      "Training epoch: 23 [800/900 (88%)]\tLoss: 0.007060\n",
      "=========> Epoch: 23 Average loss: 0.0166\n",
      "Correlation coefficient: 0.7075\n",
      "Training epoch: 24 [0/900 (0%)]\tLoss: 0.009487\n",
      "Training epoch: 24 [160/900 (18%)]\tLoss: 0.011861\n",
      "Training epoch: 24 [320/900 (35%)]\tLoss: 0.006952\n",
      "Training epoch: 24 [480/900 (53%)]\tLoss: 0.012125\n",
      "Training epoch: 24 [640/900 (70%)]\tLoss: 0.021461\n",
      "Training epoch: 24 [800/900 (88%)]\tLoss: 0.020824\n",
      "=========> Epoch: 24 Average loss: 0.0155\n",
      "Correlation coefficient: 0.6967\n",
      "Training epoch: 25 [0/900 (0%)]\tLoss: 0.008788\n",
      "Training epoch: 25 [160/900 (18%)]\tLoss: 0.021644\n",
      "Training epoch: 25 [320/900 (35%)]\tLoss: 0.003241\n",
      "Training epoch: 25 [480/900 (53%)]\tLoss: 0.010963\n",
      "Training epoch: 25 [640/900 (70%)]\tLoss: 0.009506\n",
      "Training epoch: 25 [800/900 (88%)]\tLoss: 0.014050\n",
      "=========> Epoch: 25 Average loss: 0.0140\n",
      "Correlation coefficient: 0.7103\n",
      "Training epoch: 26 [0/900 (0%)]\tLoss: 0.008984\n",
      "Training epoch: 26 [160/900 (18%)]\tLoss: 0.013035\n",
      "Training epoch: 26 [320/900 (35%)]\tLoss: 0.009862\n",
      "Training epoch: 26 [480/900 (53%)]\tLoss: 0.011082\n",
      "Training epoch: 26 [640/900 (70%)]\tLoss: 0.006605\n",
      "Training epoch: 26 [800/900 (88%)]\tLoss: 0.017408\n",
      "=========> Epoch: 26 Average loss: 0.0094\n",
      "Correlation coefficient: 0.7081\n",
      "⏹️  Epoch 26 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 9 best correlation: 0.7176\n",
      "\n",
      "========== Cross-validation Fold 10/10 ==========\n",
      "🔄 Fold 10: Using random initialization (pre-training disabled)\n",
      "Training epoch: 1 [0/900 (0%)]\tLoss: 0.932944\n",
      "Training epoch: 1 [160/900 (18%)]\tLoss: 1.271054\n",
      "Training epoch: 1 [320/900 (35%)]\tLoss: 0.967701\n",
      "Training epoch: 1 [480/900 (53%)]\tLoss: 1.126656\n",
      "Training epoch: 1 [640/900 (70%)]\tLoss: 0.323984\n",
      "Training epoch: 1 [800/900 (88%)]\tLoss: 0.261324\n",
      "=========> Epoch: 1 Average loss: 0.9342\n",
      "Correlation coefficient: 0.7165\n",
      "✅ Epoch 1: New best correlation = 0.7165\n",
      "Training epoch: 2 [0/900 (0%)]\tLoss: 0.814744\n",
      "Training epoch: 2 [160/900 (18%)]\tLoss: 0.217960\n",
      "Training epoch: 2 [320/900 (35%)]\tLoss: 0.325873\n",
      "Training epoch: 2 [480/900 (53%)]\tLoss: 0.588156\n",
      "Training epoch: 2 [640/900 (70%)]\tLoss: 0.541067\n",
      "Training epoch: 2 [800/900 (88%)]\tLoss: 0.296964\n",
      "=========> Epoch: 2 Average loss: 0.4592\n",
      "Correlation coefficient: 0.7068\n",
      "Training epoch: 3 [0/900 (0%)]\tLoss: 0.204863\n",
      "Training epoch: 3 [160/900 (18%)]\tLoss: 0.057856\n",
      "Training epoch: 3 [320/900 (35%)]\tLoss: 0.105606\n",
      "Training epoch: 3 [480/900 (53%)]\tLoss: 0.231359\n",
      "Training epoch: 3 [640/900 (70%)]\tLoss: 0.073235\n",
      "Training epoch: 3 [800/900 (88%)]\tLoss: 0.133369\n",
      "=========> Epoch: 3 Average loss: 0.1547\n",
      "Correlation coefficient: 0.6718\n",
      "Training epoch: 4 [0/900 (0%)]\tLoss: 0.096901\n",
      "Training epoch: 4 [160/900 (18%)]\tLoss: 0.081055\n",
      "Training epoch: 4 [320/900 (35%)]\tLoss: 0.026558\n",
      "Training epoch: 4 [480/900 (53%)]\tLoss: 0.057104\n",
      "Training epoch: 4 [640/900 (70%)]\tLoss: 0.038146\n",
      "Training epoch: 4 [800/900 (88%)]\tLoss: 0.054179\n",
      "=========> Epoch: 4 Average loss: 0.0626\n",
      "Correlation coefficient: 0.7033\n",
      "Training epoch: 5 [0/900 (0%)]\tLoss: 0.048088\n",
      "Training epoch: 5 [160/900 (18%)]\tLoss: 0.038558\n",
      "Training epoch: 5 [320/900 (35%)]\tLoss: 0.025642\n",
      "Training epoch: 5 [480/900 (53%)]\tLoss: 0.010471\n",
      "Training epoch: 5 [640/900 (70%)]\tLoss: 0.034714\n",
      "Training epoch: 5 [800/900 (88%)]\tLoss: 0.024022\n",
      "=========> Epoch: 5 Average loss: 0.0288\n",
      "Correlation coefficient: 0.6953\n",
      "Training epoch: 6 [0/900 (0%)]\tLoss: 0.022045\n",
      "Training epoch: 6 [160/900 (18%)]\tLoss: 0.010258\n",
      "Training epoch: 6 [320/900 (35%)]\tLoss: 0.024851\n",
      "Training epoch: 6 [480/900 (53%)]\tLoss: 0.021784\n",
      "Training epoch: 6 [640/900 (70%)]\tLoss: 0.009320\n",
      "Training epoch: 6 [800/900 (88%)]\tLoss: 0.007267\n",
      "=========> Epoch: 6 Average loss: 0.0169\n",
      "Correlation coefficient: 0.6943\n",
      "Training epoch: 7 [0/900 (0%)]\tLoss: 0.007268\n",
      "Training epoch: 7 [160/900 (18%)]\tLoss: 0.010904\n",
      "Training epoch: 7 [320/900 (35%)]\tLoss: 0.009255\n",
      "Training epoch: 7 [480/900 (53%)]\tLoss: 0.010341\n",
      "Training epoch: 7 [640/900 (70%)]\tLoss: 0.008926\n",
      "Training epoch: 7 [800/900 (88%)]\tLoss: 0.007412\n",
      "=========> Epoch: 7 Average loss: 0.0094\n",
      "Correlation coefficient: 0.6989\n",
      "Training epoch: 8 [0/900 (0%)]\tLoss: 0.005067\n",
      "Training epoch: 8 [160/900 (18%)]\tLoss: 0.001901\n",
      "Training epoch: 8 [320/900 (35%)]\tLoss: 0.002922\n",
      "Training epoch: 8 [480/900 (53%)]\tLoss: 0.005398\n",
      "Training epoch: 8 [640/900 (70%)]\tLoss: 0.003183\n",
      "Training epoch: 8 [800/900 (88%)]\tLoss: 0.025109\n",
      "=========> Epoch: 8 Average loss: 0.0067\n",
      "Correlation coefficient: 0.6951\n",
      "Training epoch: 9 [0/900 (0%)]\tLoss: 0.002961\n",
      "Training epoch: 9 [160/900 (18%)]\tLoss: 0.011976\n",
      "Training epoch: 9 [320/900 (35%)]\tLoss: 0.003963\n",
      "Training epoch: 9 [480/900 (53%)]\tLoss: 0.003867\n",
      "Training epoch: 9 [640/900 (70%)]\tLoss: 0.002933\n",
      "Training epoch: 9 [800/900 (88%)]\tLoss: 0.004344\n",
      "=========> Epoch: 9 Average loss: 0.0047\n",
      "Correlation coefficient: 0.6985\n",
      "Training epoch: 10 [0/900 (0%)]\tLoss: 0.004745\n",
      "Training epoch: 10 [160/900 (18%)]\tLoss: 0.004471\n",
      "Training epoch: 10 [320/900 (35%)]\tLoss: 0.003839\n",
      "Training epoch: 10 [480/900 (53%)]\tLoss: 0.005211\n",
      "Training epoch: 10 [640/900 (70%)]\tLoss: 0.004303\n",
      "Training epoch: 10 [800/900 (88%)]\tLoss: 0.003015\n",
      "=========> Epoch: 10 Average loss: 0.0046\n",
      "Correlation coefficient: 0.6956\n",
      "Training epoch: 11 [0/900 (0%)]\tLoss: 0.001575\n",
      "Training epoch: 11 [160/900 (18%)]\tLoss: 0.007837\n",
      "Training epoch: 11 [320/900 (35%)]\tLoss: 0.004511\n",
      "Training epoch: 11 [480/900 (53%)]\tLoss: 0.005382\n",
      "Training epoch: 11 [640/900 (70%)]\tLoss: 0.018454\n",
      "Training epoch: 11 [800/900 (88%)]\tLoss: 0.016946\n",
      "=========> Epoch: 11 Average loss: 0.0065\n",
      "Correlation coefficient: 0.6944\n",
      "Training epoch: 12 [0/900 (0%)]\tLoss: 0.005008\n",
      "Training epoch: 12 [160/900 (18%)]\tLoss: 0.007354\n",
      "Training epoch: 12 [320/900 (35%)]\tLoss: 0.005084\n",
      "Training epoch: 12 [480/900 (53%)]\tLoss: 0.006538\n",
      "Training epoch: 12 [640/900 (70%)]\tLoss: 0.004989\n",
      "Training epoch: 12 [800/900 (88%)]\tLoss: 0.003717\n",
      "=========> Epoch: 12 Average loss: 0.0074\n",
      "Correlation coefficient: 0.6939\n",
      "Training epoch: 13 [0/900 (0%)]\tLoss: 0.012160\n",
      "Training epoch: 13 [160/900 (18%)]\tLoss: 0.014561\n",
      "Training epoch: 13 [320/900 (35%)]\tLoss: 0.009470\n",
      "Training epoch: 13 [480/900 (53%)]\tLoss: 0.022818\n",
      "Training epoch: 13 [640/900 (70%)]\tLoss: 0.008527\n",
      "Training epoch: 13 [800/900 (88%)]\tLoss: 0.008591\n",
      "=========> Epoch: 13 Average loss: 0.0086\n",
      "Correlation coefficient: 0.6910\n",
      "Training epoch: 14 [0/900 (0%)]\tLoss: 0.012009\n",
      "Training epoch: 14 [160/900 (18%)]\tLoss: 0.008341\n",
      "Training epoch: 14 [320/900 (35%)]\tLoss: 0.006293\n",
      "Training epoch: 14 [480/900 (53%)]\tLoss: 0.011302\n",
      "Training epoch: 14 [640/900 (70%)]\tLoss: 0.008811\n",
      "Training epoch: 14 [800/900 (88%)]\tLoss: 0.015268\n",
      "=========> Epoch: 14 Average loss: 0.0115\n",
      "Correlation coefficient: 0.6976\n",
      "Training epoch: 15 [0/900 (0%)]\tLoss: 0.010801\n",
      "Training epoch: 15 [160/900 (18%)]\tLoss: 0.009930\n",
      "Training epoch: 15 [320/900 (35%)]\tLoss: 0.004235\n",
      "Training epoch: 15 [480/900 (53%)]\tLoss: 0.018512\n",
      "Training epoch: 15 [640/900 (70%)]\tLoss: 0.013412\n",
      "Training epoch: 15 [800/900 (88%)]\tLoss: 0.017967\n",
      "=========> Epoch: 15 Average loss: 0.0138\n",
      "Correlation coefficient: 0.6908\n",
      "Training epoch: 16 [0/900 (0%)]\tLoss: 0.012431\n",
      "Training epoch: 16 [160/900 (18%)]\tLoss: 0.012453\n",
      "Training epoch: 16 [320/900 (35%)]\tLoss: 0.024315\n",
      "Training epoch: 16 [480/900 (53%)]\tLoss: 0.016978\n",
      "Training epoch: 16 [640/900 (70%)]\tLoss: 0.009090\n",
      "Training epoch: 16 [800/900 (88%)]\tLoss: 0.015035\n",
      "=========> Epoch: 16 Average loss: 0.0147\n",
      "Correlation coefficient: 0.7066\n",
      "Training epoch: 17 [0/900 (0%)]\tLoss: 0.027062\n",
      "Training epoch: 17 [160/900 (18%)]\tLoss: 0.022351\n",
      "Training epoch: 17 [320/900 (35%)]\tLoss: 0.011008\n",
      "Training epoch: 17 [480/900 (53%)]\tLoss: 0.007956\n",
      "Training epoch: 17 [640/900 (70%)]\tLoss: 0.010026\n",
      "Training epoch: 17 [800/900 (88%)]\tLoss: 0.011217\n",
      "=========> Epoch: 17 Average loss: 0.0158\n",
      "Correlation coefficient: 0.6932\n",
      "Training epoch: 18 [0/900 (0%)]\tLoss: 0.011038\n",
      "Training epoch: 18 [160/900 (18%)]\tLoss: 0.023471\n",
      "Training epoch: 18 [320/900 (35%)]\tLoss: 0.013828\n",
      "Training epoch: 18 [480/900 (53%)]\tLoss: 0.014329\n",
      "Training epoch: 18 [640/900 (70%)]\tLoss: 0.010690\n",
      "Training epoch: 18 [800/900 (88%)]\tLoss: 0.007528\n",
      "=========> Epoch: 18 Average loss: 0.0140\n",
      "Correlation coefficient: 0.6989\n",
      "Training epoch: 19 [0/900 (0%)]\tLoss: 0.007223\n",
      "Training epoch: 19 [160/900 (18%)]\tLoss: 0.019508\n",
      "Training epoch: 19 [320/900 (35%)]\tLoss: 0.019851\n",
      "Training epoch: 19 [480/900 (53%)]\tLoss: 0.009128\n",
      "Training epoch: 19 [640/900 (70%)]\tLoss: 0.023195\n",
      "Training epoch: 19 [800/900 (88%)]\tLoss: 0.026423\n",
      "=========> Epoch: 19 Average loss: 0.0198\n",
      "Correlation coefficient: 0.6946\n",
      "Training epoch: 20 [0/900 (0%)]\tLoss: 0.017524\n",
      "Training epoch: 20 [160/900 (18%)]\tLoss: 0.027380\n",
      "Training epoch: 20 [320/900 (35%)]\tLoss: 0.019129\n",
      "Training epoch: 20 [480/900 (53%)]\tLoss: 0.024059\n",
      "Training epoch: 20 [640/900 (70%)]\tLoss: 0.040692\n",
      "Training epoch: 20 [800/900 (88%)]\tLoss: 0.008200\n",
      "=========> Epoch: 20 Average loss: 0.0174\n",
      "Correlation coefficient: 0.6930\n",
      "Training epoch: 21 [0/900 (0%)]\tLoss: 0.008877\n",
      "Training epoch: 21 [160/900 (18%)]\tLoss: 0.034003\n",
      "Training epoch: 21 [320/900 (35%)]\tLoss: 0.004660\n",
      "Training epoch: 21 [480/900 (53%)]\tLoss: 0.008091\n",
      "Training epoch: 21 [640/900 (70%)]\tLoss: 0.011728\n",
      "Training epoch: 21 [800/900 (88%)]\tLoss: 0.006790\n",
      "=========> Epoch: 21 Average loss: 0.0119\n",
      "Correlation coefficient: 0.6922\n",
      "⏹️  Epoch 21 early stopping (no improvement for 20 epochs)\n",
      "🏁 Fold 10 best correlation: 0.7165\n",
      "\n",
      "===== Cross-validation completed =====\n",
      "Best correlations for each fold: [0.5562 0.7659 0.7653 0.5596 0.7275 0.7068 0.6806 0.6773 0.7176 0.7165]\n",
      "Mean correlation: 0.6874 ± 0.0705\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 10-fold cross-validation\n",
    "# =============================================================================\n",
    "\n",
    "# Execute 10-fold cross-validation\n",
    "all_best_correlations = cross_validation_phenotype_prediction(\n",
    "    genotype_encoded, \n",
    "    phenotype_normalized, \n",
    "    phenotype_scaler,\n",
    "    device,config=config\n",
    ")\n",
    "\n",
    "print(\"\\n===== Cross-validation completed =====\")\n",
    "print(\"Best correlations for each fold:\", np.round(all_best_correlations, 4))\n",
    "print(f\"Mean correlation: {np.mean(all_best_correlations):.4f} ± {np.std(all_best_correlations):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 720.95 seconds\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Results statistics and summary\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_runtime_summary(start_time):\n",
    "    \"\"\"Calculate runtime statistics\"\"\"\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total runtime: {elapsed_time:.2f} seconds\")\n",
    "    return elapsed_time\n",
    "\n",
    "# Calculate runtime\n",
    "total_runtime = calculate_runtime_summary(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ratio: 0.0\n",
      "Mean correlation: 0.6874\n",
      "Standard deviation: 0.0705\n",
      "Best correlation: 0.7659\n",
      "Worst correlation: 0.5562\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Final results output\n",
    "# =============================================================================\n",
    "\n",
    "def print_final_results(missing_ratio, correlations):\n",
    "    \"\"\"Print final results\"\"\"\n",
    "    print(f\"Missing ratio: {missing_ratio}\")\n",
    "    mean_correlation = np.mean(correlations)\n",
    "    std_correlation = np.std(correlations)\n",
    "    \n",
    "    print(f\"Mean correlation: {mean_correlation:.4f}\")\n",
    "    print(f\"Standard deviation: {std_correlation:.4f}\")\n",
    "    print(f\"Best correlation: {np.max(correlations):.4f}\")\n",
    "    print(f\"Worst correlation: {np.min(correlations):.4f}\")\n",
    "    \n",
    "    return mean_correlation\n",
    "\n",
    "# Output final results\n",
    "final_mean_correlation = print_final_results(config.MISSING_RATIO, all_best_correlations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
